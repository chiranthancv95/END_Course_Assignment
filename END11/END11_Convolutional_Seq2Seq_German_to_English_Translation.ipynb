{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END11 - Convolutional Seq2Seq - German to English Translation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2Vquqi7LHy7"
      },
      "source": [
        "# Convolutional Seq2Seq\n",
        "In this approach, we are using Convolutional Neural Networks(CNNs) and Residual Networks in the likes of Resnet model from Microsoft.<br>\n",
        "Here, we use the sequence to sequence modelling approach to predict the future translations of the English language to German language.<br>\n",
        "\n",
        "Since, we already know CNNs are very good at extracting features from an image, so here we try to use it's feature extraction on the text data.<br>\n",
        "\n",
        "We use, 1x3 filters(tri-gram) or kernels to get extract features over text. This kernel size helps in convolving all the text completely without any redundancy, since it can ignore the sos and eos of the input text.<br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-seq2seq/raw/9479fcb532214ad26fd4bda9fcf081a05e1aaf4e/assets/convseq2seq0.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQcGmBR3BwtZ"
      },
      "source": [
        "# Introduction\r\n",
        "\r\n",
        "In this notebook, we'll be building a machine learning model to go from once sequence to another, using PyTorch and TorchText. This will be done on German to English translations, but the models can be applied to any problem that involves going from one sequence to another, such as summarization, i.e. going from a sequence to a shorter sequence in the same language.\r\n",
        "\r\n",
        "Before we delve deep into the code, lets first understand the model architecture as mentioned in the paper.\r\n",
        "\r\n",
        "Lets recall our general RNN based encoder decoder model, \r\n",
        "\r\n",
        "<!-- ![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq10.png?raw=1)\r\n",
        "\r\n",
        "In the general case, we use our encoder (teal block), basically a RNN layer over the embedded source sequence to create context. All the encoded states from the encoder along with the context go to the attention block, this attention block predicts sort of number called alpha which indicates the amplitude of all the encoded states going forward. Attention places different focus on different words by assigning each word with a alpha score. We then use that context vector with the decoder (blue block), we also pass a vector representation (attention vector) from every encoder time step to the decoder. This helps the network to focus on right word of the input sequence so that it can make appropriate translations to predict the next words of the target sequence -->\r\n",
        "\r\n",
        "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq1.png?raw=1)\r\n",
        "\r\n",
        "We use our encoder (green) over the embedded source sequence (yellow) to create a context vector (red). We then use that context vector with the decoder (blue) and a linear layer (purple) to generate the target sentence.\r\n",
        "\r\n",
        "# How convolutional sequence to sequence model work?\r\n",
        "\r\n",
        "An architecture proposed by authors for sequence to sequence\r\n",
        "modeling is entirely convolutional.\r\n",
        "Below diagram outlines the structure of convolutional sequence to sequence model.\r\n",
        "![](https://github.com/bentrevett/pytorch-seq2seq/raw/9479fcb532214ad26fd4bda9fcf081a05e1aaf4e/assets/convseq2seq0.png)\r\n",
        "\r\n",
        "Like any RNN based sequence to sequence structure CNN based model uses encoder decoder architecture, however here both encoder and decoder are composed of stacked convolutional layers with a special type of activation function called Gated Linear Units. In the middle there is a attention function. The encoder extracts features from the source sequence, while decoder learns to estimate the function that maps the encoders hidden state and its previous generated words to the next word. The attention tells the decoder which hidden states of the encoder to focus on. \r\n",
        "\r\n",
        "A concept of **positional embedding**, is been introduced in this model. Well, what do we mean by positional embedding?\r\n",
        "\r\n",
        "In CNN, we process all the words in a sequence simultaneously, it is impossible to capture the sequence order information like we do in RNNs (a timeseries based model). In order to use the sequence information of the sequence, the absolute position information of the tokens needs to be injected into the model and we need to explicity sent this information to the network.  This works just like a regular word embedding but instead of mapping words, it maps the absolute position of a word to a dense vector. The position embeding output will be added on the word embeding. With this additional information, the model knows which part of the context it is handling.\r\n",
        "\r\n",
        "\r\n",
        "<!-- RNN which is a timeseries based model, we send and process the words sequentially. However, in CNN we need to send all the words simultaneously. The problem with this is the network will not know the order / location / position of the sequence word being sent. -->\r\n",
        "\r\n",
        "\r\n",
        "![positional emd.PNG](https://drive.google.com/uc?export=view&id=1UHgIGYWVin23pHKw8TiU7WlLL3vOZ_r8)\r\n",
        "\r\n",
        "The paper also applies residual connection between the blocks in both the encoder and the decoder, which allows for deeper convolutional network. \r\n",
        "\r\n",
        "### Why residual connection?\r\n",
        "\r\n",
        "Models with many layers often rely on shortcut or residual connections. When we stack up convolutional layers to form a deeper model, it becomes harder and harder to optimize since the model has a lot of parameters, resulting in poor performance and also the gradient values start exploding and becomes very difficult to handle. This is solved by adding a residual block (skip connections) i.e to add the previous blocks output onto the current block directly. This technique makes the learning process easier and faster, enabling the model to go deeper, also helps improve the accuracy.\r\n",
        "\r\n",
        "\r\n",
        "<!-- Instead of trying to approximate the direct mapping function H(x) from the input to the output, we estimate the residual mapping function F(x), which is essentially H(x) - input of the current block. We can think of F(x) is modifying x to approximate H(x), instead of learning a whole new mapping function.  -->\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez4d1UzN9NZH",
        "outputId": "1f0a4117-802c-43f9-9462-2e1ecd8de44c"
      },
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 30.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 25.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61kB 22.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 27.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.95 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2MRSNsWDXaJ"
      },
      "source": [
        "## Import Modules\r\n",
        "\r\n",
        "First, we'll import all the modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAw4EP9cOHSB"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "from torchtext.datasets import Multi30k\r\n",
        "from torchtext.data import Field, BucketIterator\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.ticker as ticker\r\n",
        "\r\n",
        "import spacy\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import random\r\n",
        "import math\r\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYGqJwJ-DjfS"
      },
      "source": [
        "Next, we'll set the random seed for reproducability. Till the kernel is alive, the seed is a valid. If we shutdown the kernel the seed will be reset, next time when the kernel is restart we will not be able to reproduce same result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PGBbGe9OTR0"
      },
      "source": [
        "SEED = 1234\r\n",
        "\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yehZL6jOf-8",
        "outputId": "a01883d0-73da-410b-fb8f-429d2d48e88a"
      },
      "source": [
        "!python -m spacy download en\r\n",
        "!python -m spacy download de"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (51.3.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 12.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (51.3.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907057 sha256=25b8a8c8b3a301942c7beb6c83ddc1f687d66097728aeee9f57bd41c8ec4a100\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bf8x3diz/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3lqh4-ZDrbD"
      },
      "source": [
        "Next, we'll create the tokenizers. A tokenizer is used to turn a string containing a sentence into a list of individual tokens that make up that string, e.g. \"good morning!\" becomes [\"good\", \"morning\", \"!\"]. We'll start talking about the sentences being a sequence of tokens from now, instead of saying they're a sequence of words. What's the difference? Well, \"good\" and \"morning\" are both words and tokens, but \"!\" is a token, not a word.\r\n",
        "\r\n",
        "spaCy has model for each language (\"de\" for German and \"en\" for English) which need to be loaded so we can access the tokenizer of each model.\r\n",
        "\r\n",
        "Note: the models must first be downloaded using the following on the command line:\r\n",
        "\r\n",
        "    python -m spacy download en\r\n",
        "    python -m spacy download de"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvCoP46UCEDb"
      },
      "source": [
        "We load the models as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2YHL1DPOVKD"
      },
      "source": [
        "spacy_de = spacy.load('de')\r\n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw7dzCjFD1Wf"
      },
      "source": [
        "Next, we create the tokenizer functions. These can be passed to TorchText and will take in the sentence as a string and return the sentence as a list of tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdIpGUYDOWu1"
      },
      "source": [
        "def tokenize_de(text):\r\n",
        "    \"\"\"\r\n",
        "    Tokenizes German text from a string into a list of strings\r\n",
        "    \"\"\"\r\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]\r\n",
        "\r\n",
        "def tokenize_en(text):\r\n",
        "    \"\"\"\r\n",
        "    Tokenizes English text from a string into a list of strings\r\n",
        "    \"\"\"\r\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKgcfQbTD9Nv"
      },
      "source": [
        "TorchText's Fields handle how data should be processed.\r\n",
        "\r\n",
        "We set the tokenize argument to the correct tokenization function for each, with German being the SRC (source) field and English being the TRG (target) field. The field also appends the \"start of sequence\" and \"end of sequence\" tokens via the init_token and eos_token arguments, and converts all words to lowercase.\r\n",
        "\r\n",
        "RNN Models by default expects the sequence to be of shape [sequence length, batch size] so TorchText will return batches of tensors in the same shape. Since we are using CNNs,  they expect batch_size to be first, so we set batch_first=True so that TorchText can return the tensors of dimension [batch size, sequence length]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6SkU5t4OoJy"
      },
      "source": [
        "SRC = Field(tokenize = tokenize_de, \r\n",
        "            init_token = '<sos>', \r\n",
        "            eos_token = '<eos>', \r\n",
        "            lower = True, \r\n",
        "            batch_first = True)\r\n",
        "\r\n",
        "TRG = Field(tokenize = tokenize_en, \r\n",
        "            init_token = '<sos>', \r\n",
        "            eos_token = '<eos>', \r\n",
        "            lower = True, \r\n",
        "            batch_first = True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jofw0oGFs4B"
      },
      "source": [
        "Next, we download and load the train, validation and test data.\r\n",
        "\r\n",
        "The dataset we'll be using is the Multi30k dataset. This is a dataset with ~30,000 parallel English, German and French sentences, each with ~12 words per sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh30BF32Opfh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c249cc7-98c7-41f6-e738-461bfe23e281"
      },
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(exts=('.de', '.en'), \r\n",
        "                                                    fields=(SRC, TRG))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 950kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 271kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 268kB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPFoPv66C8Oc"
      },
      "source": [
        "Then create our vocabulary, converting all tokens appearing less than twice into tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQapMRRGOqrE"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\r\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRBcLomrF-Lj"
      },
      "source": [
        "We also need to define a torch.device. This is used to tell TorchText to put the tensors on the GPU or not. We use the torch.cuda.is_available() function, which will return True if a GPU is detected on our computer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IG349zyOsIG"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toB0WfY8F1Di"
      },
      "source": [
        "The final step of preparing the data is to create the iterators. These can be iterated on to return a batch of data which will have a src attribute (the PyTorch tensors containing a batch of numericalized source sentences) and a trg attribute (the PyTorch tensors containing a batch of numericalized target sentences). Numericalized is just a fancy way of saying they have been converted from a sequence of readable tokens to a sequence of corresponding indexes, using the vocabulary.\r\n",
        "\r\n",
        "When we get a batch of examples using an iterator, we use a BucketIterator instead of the standard Iterator as it creates batches in such a way that it minimizes the amount of padding in both the source and target sentences.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3ltm3BEOtgH"
      },
      "source": [
        "BATCH_SIZE = 128\r\n",
        "\r\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\r\n",
        "    (train_data, valid_data, test_data), \r\n",
        "     batch_size = BATCH_SIZE,\r\n",
        "     device = device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7_dEuyGOwHO"
      },
      "source": [
        "## Encoder\r\n",
        "\r\n",
        "Let's now have a closer look at the Encoder structure.\r\n",
        "\r\n",
        "![](https://github.com/bentrevett/pytorch-seq2seq/raw/9479fcb532214ad26fd4bda9fcf081a05e1aaf4e/assets/convseq2seq1.png)\r\n",
        "\r\n",
        "- We take the German sentence add padding at the start <sos> and end of the sentence <eos> and split those into tokens. This is because, the CNN layer is going to reduce the length of the sentence, to maintain same sentence length we add padding.\r\n",
        "- We first send it to the embeding layer to get the word embedding, we also need to encode the position of the word, so we will be literally sending the position(index postion of the words) to another similar embeding layer to get the positional embeddings. \r\n",
        "- We then do a element wise sum of word embedding and postional embedding, that is going to result in a combined embedding which is a element wise vector (This layer knowns the word and also has encoded even the location of the word) .\r\n",
        "- This vector goes into a Fully connected layer because we need to convert it into a particular dimention and also, to help increase capacity and extract information, basically to convert these simple numbers into something which is more complex (like rearranging of features).\r\n",
        "- The ouput of each of these FC layer is simultaneously sent to the multiple convolution blocks.\r\n",
        "- For each of the information that is going into the convolutional block, we are going to get individual outputs.\r\n",
        "- This output is again sent to another fully connected layer, because the output of the convolution need to be converted into the embedding dimension of the encoder.\r\n",
        "- The final vector will have the embedding equal to the number of dimension we want.\r\n",
        "- We also add a skip connection the output of the final FC layer gets added with the element wise sum of word and position embeding , i.e we are sending the whole word along with the position of the word to the decoder as convolutional layer might loose the positional information.\r\n",
        "\r\n",
        "Finally, from the encoder block we will be sending two outputs to the decoder, one is the conved output and another is combined vector (which is combination of transformed vector and embedding vector)\r\n",
        "i.e suppose we have 6 tokens, we will be getting 12 context vectors, 2 context vectors per token, one from conved and another from combined. \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "## Convolutional Blocks\r\n",
        "\r\n",
        "Lets now see the convolutional block within encoder architecture\r\n",
        "\r\n",
        "![](https://raw.githubusercontent.com/bentrevett/pytorch-seq2seq/9479fcb532214ad26fd4bda9fcf081a05e1aaf4e/assets/convseq2seq2.png)\r\n",
        "\r\n",
        "\r\n",
        "- As mentioned earlier we pass the padded input sentence to the CNN block, this is because the CNN layer is going to reduce the length of the sentence, and we need to ensure that the length of the input sentence getting into the convolution block is equal to the length of the sentence going out of the convolution block.\r\n",
        "- We will be then convolving the padded output using a kernel size of 3 (odd size)\r\n",
        "- The output of this is sent to a special kind of acivation GLU (Gated Linear Unit) activation.\r\n",
        "\r\n",
        "    ### How GLU activation works?\r\n",
        "    The output of convolutional layer i.e input to GLU is split into two halves A and B, half the input (A) would go to sigmoid and we would then do a element wise sum of both. Sigmoid acts as a gate, determining which part of B are relevant to the current context. The larger the values of entry in A the more important that corresponding entry in B is. The gating mechanisn of the models enables to select the effective parts of the input features in preducting the next words. Since the GLU is going to reduce the input to half, we would be doubling the input to the convolution block.\r\n",
        "\r\n",
        "    ![GLU.PNG](https://drive.google.com/uc?export=view&id=1Uu_ZOvkISyBdB517Ik-FFNebBJeVWItQ)\r\n",
        "\r\n",
        "- Then we add a residual connection i.e The output of the combined vector is going to be added as a skip connection to the output of the GLU, this done just to avoid any issues associated with the convolutional layers, this skip connections ensures smooth flow of gradients\r\n",
        "\r\n",
        "This concludes a single convolutional block. Subsequent blocks take the output of the previous block and perform the same steps. Each block has their own parameters, they are not shared between blocks. The output of the last block goes back to the main encoder - where it is fed through a linear layer to get the conved output and then elementwise summed with the embedding of the token to get the combined output.\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEjxwGUxOun-"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 input_dim, \r\n",
        "                 emb_dim, \r\n",
        "                 hid_dim, \r\n",
        "                 n_layers, \r\n",
        "                 kernel_size, \r\n",
        "                 dropout, \r\n",
        "                 device,\r\n",
        "                 max_length = 100):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        assert kernel_size % 2 == 1, \"Kernel size must be odd!\"\r\n",
        "        \r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([0.5])).to(device)\r\n",
        "        \r\n",
        "        #call embedding layers\r\n",
        "        self.tok_embedding = nn.Embedding(input_dim, emb_dim) #input dim and emd dim\r\n",
        "        self.pos_embedding = nn.Embedding(max_length, emb_dim) # this needs to know max length (as we can't handle every lenth of the sequence, we need to have a stop)\r\n",
        "\r\n",
        "        #add linear layer to the output of the embedding\r\n",
        "        self.emb2hid = nn.Linear(emb_dim, hid_dim)\r\n",
        "        self.hid2emb = nn.Linear(hid_dim, emb_dim)\r\n",
        "        \r\n",
        "        self.convs = nn.ModuleList([nn.Conv1d(in_channels = hid_dim, #how many input channels - hid_dim\r\n",
        "                                              out_channels = 2 * hid_dim, # how many output channels - \r\n",
        "                                              kernel_size = kernel_size, # kernel size 3x1\r\n",
        "                                              padding = (kernel_size - 1) // 2) # padding enabled\r\n",
        "                                    for _ in range(n_layers)])\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, src):\r\n",
        "        \r\n",
        "        #src = [batch size, src len]\r\n",
        "        \r\n",
        "        batch_size = src.shape[0]\r\n",
        "        src_len = src.shape[1]\r\n",
        "        \r\n",
        "        #create position tensor\r\n",
        "        # we need to repeat this because we need the position for all the sentence in the batch, so repeat at batch_size at the distribution of 1\r\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device) \r\n",
        "        \r\n",
        "        #pos = [0, 1, 2, 3, ..., src len - 1]\r\n",
        "        \r\n",
        "        #pos = [batch size, src len]\r\n",
        "        \r\n",
        "        #embed tokens and positions\r\n",
        "        tok_embedded = self.tok_embedding(src)\r\n",
        "        pos_embedded = self.pos_embedding(pos)\r\n",
        "        \r\n",
        "        #tok_embedded = pos_embedded = [batch size, src len, emb dim]\r\n",
        "        \r\n",
        "        #combine embeddings by elementwise summing\r\n",
        "        embedded = self.dropout(tok_embedded + pos_embedded)\r\n",
        "        \r\n",
        "        #embedded = [batch size, src len, emb dim]\r\n",
        "        \r\n",
        "        #pass embedded through linear layer to convert from emb dim to hid dim\r\n",
        "        conv_input = self.emb2hid(embedded)\r\n",
        "        \r\n",
        "        #conv_input = [batch size, src len, hid dim]\r\n",
        "        \r\n",
        "        #permute for convolutional layer\r\n",
        "        conv_input = conv_input.permute(0, 2, 1) \r\n",
        "        \r\n",
        "        #conv_input = [batch size, hid dim, src len]\r\n",
        "        \r\n",
        "        #begin convolutional blocks...\r\n",
        "        \r\n",
        "        for i, conv in enumerate(self.convs):\r\n",
        "        \r\n",
        "            #pass through convolutional layer\r\n",
        "            conved = conv(self.dropout(conv_input))\r\n",
        "\r\n",
        "            #conved = [batch size, 2 * hid dim, src len]\r\n",
        "\r\n",
        "            #pass through GLU activation function\r\n",
        "            conved = F.glu(conved, dim = 1) # specifies the dimension in which we are going to divide the GLU\r\n",
        "\r\n",
        "            #conved = [batch size, hid dim, src len]\r\n",
        "            \r\n",
        "            #apply residual connection\r\n",
        "            # whenever we add two number, we double the amplitude this will cause sudden increase in the overall gradients required\r\n",
        "            # so whenever we add vextores we need to scale them, else the numbers can explode and BP may suffer\r\n",
        "            conved = (conved + conv_input) * self.scale\r\n",
        "\r\n",
        "            #conved = [batch size, hid dim, src len]\r\n",
        "            \r\n",
        "            #set conv_input to conved for next loop iteration\r\n",
        "            conv_input = conved\r\n",
        "        \r\n",
        "        #...end convolutional blocks\r\n",
        "        \r\n",
        "        #permute and convert back to emb dim\r\n",
        "        conved = self.hid2emb(conved.permute(0, 2, 1))\r\n",
        "        \r\n",
        "        #conved = [batch size, src len, emb dim]\r\n",
        "        \r\n",
        "        #elementwise sum output (conved) and input (embedded) to be used for attention\r\n",
        "        combined = (conved + embedded) * self.scale\r\n",
        "        \r\n",
        "        #combined = [batch size, src len, emb dim]\r\n",
        "        \r\n",
        "        return conved, combined"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUEAan-FPIoJ"
      },
      "source": [
        "## Decoder \r\n",
        "\r\n",
        "The Decoder is very similar to Encoder, but with few changes.\r\n",
        "\r\n",
        "![](https://raw.githubusercontent.com/bentrevett/pytorch-seq2seq/9479fcb532214ad26fd4bda9fcf081a05e1aaf4e/assets/convseq2seq3.png)\r\n",
        "\r\n",
        "- We will passing the whole output for the prediction, like encoder we will first pass the tokens to the embeding layer to get the word and postional embedding.\r\n",
        "- Add both the word and postional embedding using element wise sum, pass it to the fully connected layer, which then goes to the convolutional layer.\r\n",
        "- The convolutional layer accepts two additional inputs i.e the encoder conved and encoder combined (this is to feed encoder information into the decoder), we also pass the embedding vector as a residual connection to the convolution layer. Unlike the encoder, the resnet connection or skip connection goes only to the convolution block it doesnot go to the output of the convolution block because we have to use the information to predict the output.\r\n",
        "- This goes to two layer linear network (FC layer) to make the final prediction.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "## Decoder Conv Blocks\r\n",
        "\r\n",
        "Let's now see the decoder convolutional blocks, this is similar to the one within encoder. However there are few changes.\r\n",
        "\r\n",
        "![](https://raw.githubusercontent.com/bentrevett/pytorch-seq2seq/9479fcb532214ad26fd4bda9fcf081a05e1aaf4e/assets/convseq2seq4.png)\r\n",
        "\r\n",
        "For encoder the input sequence is padded so that the input and output lengths are the same and we would pad the target sentence in the decoder aswell for the same reason. However, for decoder we only pad at the beginning of the sentence, the padding makes sure the target of the decoder is shifted by one word from its input. Since we are processing all the target sequence simultaneously, so we need a method of not only allowing the filter to translate the token that we have to the next stage, but we also need to make sure that the model will not learn to output the next word in the sequence by directly copying the next word, without actually learning how to translate. \r\n",
        "\r\n",
        "<!-- the attension in the middle can be computed simultaneously for the length of the kernel (queries) to parallelize the training process. However, during testing we need to wait for the next word to be generated in order to proceed to the next time step -->\r\n",
        "\r\n",
        "If we don't pad it at the beginning (as shown below), then the model will see the next word while convolving and would literally be copying that to the output, without learning to translate\r\n",
        "\r\n",
        "![](https://raw.githubusercontent.com/bentrevett/pytorch-seq2seq/9479fcb532214ad26fd4bda9fcf081a05e1aaf4e/assets/convseq2seq5.png)\r\n",
        "\r\n",
        "\r\n",
        "## Attention\r\n",
        "\r\n",
        "The model also adds a attention in every decoder layer and demonstrate that each attention layer only adds a negligible amount of overhead.The model uses both encoder conved and encoder combined, to figure out where exactly the encoder want the model to focus on while making the prediction\r\n",
        "- Firstly, we take the conved output of a word from the decoder, do a element wise sum with the decoder input embedding to generate combined embedding\r\n",
        "- Next, we calculate the attention between the above generated combined embedding and the encoder conved, to find how much it matches with the encoded conved \r\n",
        "- Then, this is used to calculate the weighted sum over the encoded combined to apply the attention.\r\n",
        "- This is then projected back up to the hidden dimenson size and a residual connection to the initial input is applied to the attention layer.\r\n",
        "\r\n",
        "This can be seen as attention with multiple ’hops’ compared to single step attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSyBwu30PH-2"
      },
      "source": [
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 output_dim, \r\n",
        "                 emb_dim, \r\n",
        "                 hid_dim, \r\n",
        "                 n_layers, \r\n",
        "                 kernel_size, \r\n",
        "                 dropout, \r\n",
        "                 trg_pad_idx, \r\n",
        "                 device,\r\n",
        "                 max_length = 100):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.kernel_size = kernel_size\r\n",
        "        self.trg_pad_idx = trg_pad_idx\r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([0.5])).to(device)\r\n",
        "        \r\n",
        "        self.tok_embedding = nn.Embedding(output_dim, emb_dim)\r\n",
        "        self.pos_embedding = nn.Embedding(max_length, emb_dim)\r\n",
        "        \r\n",
        "        self.emb2hid = nn.Linear(emb_dim, hid_dim)\r\n",
        "        self.hid2emb = nn.Linear(hid_dim, emb_dim)\r\n",
        "        \r\n",
        "        self.attn_hid2emb = nn.Linear(hid_dim, emb_dim)\r\n",
        "        self.attn_emb2hid = nn.Linear(emb_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.fc_out = nn.Linear(emb_dim, output_dim)\r\n",
        "        \r\n",
        "        self.convs = nn.ModuleList([nn.Conv1d(in_channels = hid_dim, \r\n",
        "                                              out_channels = 2 * hid_dim, \r\n",
        "                                              kernel_size = kernel_size)\r\n",
        "                                    for _ in range(n_layers)])\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "      \r\n",
        "    def calculate_attention(self, embedded, conved, encoder_conved, encoder_combined):\r\n",
        "        \r\n",
        "        #embedded = [batch size, trg len, emb dim]\r\n",
        "        #conved = [batch size, hid dim, trg len]\r\n",
        "        #encoder_conved = encoder_combined = [batch size, src len, emb dim]\r\n",
        "        \r\n",
        "        #permute and convert back to emb dim\r\n",
        "        conved_emb = self.attn_hid2emb(conved.permute(0, 2, 1))\r\n",
        "        \r\n",
        "        #conved_emb = [batch size, trg len, emb dim]\r\n",
        "        \r\n",
        "        combined = (conved_emb + embedded) * self.scale\r\n",
        "        \r\n",
        "        #combined = [batch size, trg len, emb dim]\r\n",
        "                \r\n",
        "        energy = torch.matmul(combined, encoder_conved.permute(0, 2, 1))\r\n",
        "        \r\n",
        "        #energy = [batch size, trg len, src len]\r\n",
        "        \r\n",
        "        attention = F.softmax(energy, dim=2)\r\n",
        "        \r\n",
        "        #attention = [batch size, trg len, src len]\r\n",
        "            \r\n",
        "        attended_encoding = torch.matmul(attention, encoder_combined)\r\n",
        "        \r\n",
        "        #attended_encoding = [batch size, trg len, emd dim]\r\n",
        "        \r\n",
        "        #convert from emb dim -> hid dim\r\n",
        "        attended_encoding = self.attn_emb2hid(attended_encoding)\r\n",
        "        \r\n",
        "        #attended_encoding = [batch size, trg len, hid dim]\r\n",
        "        \r\n",
        "        #apply residual connection\r\n",
        "        attended_combined = (conved + attended_encoding.permute(0, 2, 1)) * self.scale\r\n",
        "        \r\n",
        "        #attended_combined = [batch size, hid dim, trg len]\r\n",
        "        \r\n",
        "        return attention, attended_combined\r\n",
        "        \r\n",
        "    def forward(self, trg, encoder_conved, encoder_combined):\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len]\r\n",
        "        #encoder_conved = encoder_combined = [batch size, src len, emb dim]\r\n",
        "                \r\n",
        "        batch_size = trg.shape[0]\r\n",
        "        trg_len = trg.shape[1]\r\n",
        "            \r\n",
        "        #create position tensor\r\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\r\n",
        "        \r\n",
        "        #pos = [batch size, trg len]\r\n",
        "        \r\n",
        "        #embed tokens and positions\r\n",
        "        tok_embedded = self.tok_embedding(trg)\r\n",
        "        pos_embedded = self.pos_embedding(pos)\r\n",
        "        \r\n",
        "        #tok_embedded = [batch size, trg len, emb dim]\r\n",
        "        #pos_embedded = [batch size, trg len, emb dim]\r\n",
        "        \r\n",
        "        #combine embeddings by elementwise summing\r\n",
        "        embedded = self.dropout(tok_embedded + pos_embedded)\r\n",
        "        \r\n",
        "        #embedded = [batch size, trg len, emb dim]\r\n",
        "        \r\n",
        "        #pass embedded through linear layer to go through emb dim -> hid dim\r\n",
        "        conv_input = self.emb2hid(embedded)\r\n",
        "        \r\n",
        "        #conv_input = [batch size, trg len, hid dim]\r\n",
        "        \r\n",
        "        #permute for convolutional layer\r\n",
        "        conv_input = conv_input.permute(0, 2, 1) \r\n",
        "        \r\n",
        "        #conv_input = [batch size, hid dim, trg len]\r\n",
        "        \r\n",
        "        batch_size = conv_input.shape[0]\r\n",
        "        hid_dim = conv_input.shape[1]\r\n",
        "        \r\n",
        "        for i, conv in enumerate(self.convs):\r\n",
        "        \r\n",
        "            #apply dropout\r\n",
        "            conv_input = self.dropout(conv_input)\r\n",
        "        \r\n",
        "            #need to pad so decoder can't \"cheat\"\r\n",
        "            padding = torch.zeros(batch_size, \r\n",
        "                                  hid_dim, \r\n",
        "                                  self.kernel_size - 1).fill_(self.trg_pad_idx).to(self.device)\r\n",
        "                \r\n",
        "            padded_conv_input = torch.cat((padding, conv_input), dim = 2)\r\n",
        "        \r\n",
        "            #padded_conv_input = [batch size, hid dim, trg len + kernel size - 1]\r\n",
        "        \r\n",
        "            #pass through convolutional layer\r\n",
        "            conved = conv(padded_conv_input)\r\n",
        "\r\n",
        "            #conved = [batch size, 2 * hid dim, trg len]\r\n",
        "            \r\n",
        "            #pass through GLU activation function\r\n",
        "            conved = F.glu(conved, dim = 1)\r\n",
        "\r\n",
        "            #conved = [batch size, hid dim, trg len]\r\n",
        "            \r\n",
        "            #calculate attention\r\n",
        "            attention, conved = self.calculate_attention(embedded, \r\n",
        "                                                         conved, \r\n",
        "                                                         encoder_conved, \r\n",
        "                                                         encoder_combined)\r\n",
        "            \r\n",
        "            #attention = [batch size, trg len, src len]\r\n",
        "            \r\n",
        "            #apply residual connection\r\n",
        "            conved = (conved + conv_input) * self.scale\r\n",
        "            \r\n",
        "            #conved = [batch size, hid dim, trg len]\r\n",
        "            \r\n",
        "            #set conv_input to conved for next loop iteration\r\n",
        "            conv_input = conved\r\n",
        "            \r\n",
        "        conved = self.hid2emb(conved.permute(0, 2, 1))\r\n",
        "         \r\n",
        "        #conved = [batch size, trg len, emb dim]\r\n",
        "            \r\n",
        "        output = self.fc_out(self.dropout(conved))\r\n",
        "        \r\n",
        "        #output = [batch size, trg len, output dim]\r\n",
        "            \r\n",
        "        return output, attention"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPovfZglxRj9"
      },
      "source": [
        "# Seq2Seq\r\n",
        "\r\n",
        "For the final part of the implemenetation, we'll implement the seq2seq model. This will stitch the Encoder and Decoder together:\r\n",
        "\r\n",
        "- Firstly <eos> token is sliced off from the target sentence as we do not input this token to the decoder.\r\n",
        "- The encoder receives the input/source sentence and produces two context vectors for each word:\r\n",
        "  - encoder_conved (output from final encoder conv. block) and \r\n",
        "  - encoder_combined [encoder_conved plus (elementwise) src embedding plus positional embeddings]\r\n",
        "- The decoder takes in all the target sentence at one to produce the prediction of output/target sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H56wQXdqPb1_"
      },
      "source": [
        "class Seq2Seq(nn.Module):\r\n",
        "    def __init__(self, encoder, decoder):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.encoder = encoder\r\n",
        "        self.decoder = decoder\r\n",
        "        \r\n",
        "    def forward(self, src, trg):\r\n",
        "        \r\n",
        "        #src = [batch size, src len]\r\n",
        "        #trg = [batch size, trg len - 1] (<eos> token sliced off the end)\r\n",
        "           \r\n",
        "        #calculate z^u (encoder_conved) and (z^u + e) (encoder_combined)\r\n",
        "        #encoder_conved is output from final encoder conv. block\r\n",
        "        #encoder_combined is encoder_conved plus (elementwise) src embedding plus \r\n",
        "        #  positional embeddings \r\n",
        "        encoder_conved, encoder_combined = self.encoder(src)\r\n",
        "            \r\n",
        "        #encoder_conved = [batch size, src len, emb dim]\r\n",
        "        #encoder_combined = [batch size, src len, emb dim]\r\n",
        "        \r\n",
        "        #calculate predictions of next words\r\n",
        "        #output is a batch of prediced) and (z^u + e) (encoder_combined)\r\n",
        "        #encoder_conved is output from final encoder conv. block\r\n",
        "        #encoder_combined is encoder_conved plus (elementwise) src embedding plus \r\n",
        "        #  positional embeddings \r\n",
        "        encoder_conved, encoder_combined = self.encoder(src)\r\n",
        "            \r\n",
        "        #encoder_conved = [batch size, src len, emb dim]\r\n",
        "        #encoder_combined = [batch size, src len, emb dim]\r\n",
        "        \r\n",
        "        #calculate predictions of next words\r\n",
        "        #output is a batch of predictions for each word in the trg sentence\r\n",
        "        #attention a batch of attention scores across the src sentence for \r\n",
        "        #  each word in the trg sentence\r\n",
        "        output, attention = self.decoder(trg, encoder_conved, encoder_combined)\r\n",
        "        \r\n",
        "        #output = [batch size, trg len - 1, output dim]\r\n",
        "        #attention = [batch size, trg len - 1, src len]\r\n",
        "        \r\n",
        "        return output, attention"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHIZw0LNMREd"
      },
      "source": [
        "# Training the Seq2Seq Model\r\n",
        "Now we have our model implemented, we can begin training it.\r\n",
        "\r\n",
        "First, we'll initialize our model, we define all of the hyperparameters, initialize the encoder and decoder, and initialize the overall model - placing it on the GPU if we have one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBUcXsz0PdUB"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\r\n",
        "OUTPUT_DIM = len(TRG.vocab)\r\n",
        "EMB_DIM = 256\r\n",
        "HID_DIM = 512 # each conv. layer has 2 * hid_dim filters\r\n",
        "ENC_LAYERS = 10 # number of conv. blocks in encoder\r\n",
        "DEC_LAYERS = 10 # number of conv. blocks in decoder\r\n",
        "ENC_KERNEL_SIZE = 3 # must be odd!\r\n",
        "DEC_KERNEL_SIZE = 3 # can be even or odd\r\n",
        "ENC_DROPOUT = 0.25\r\n",
        "DEC_DROPOUT = 0.25\r\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\r\n",
        "    \r\n",
        "enc = Encoder(INPUT_DIM, EMB_DIM, HID_DIM, ENC_LAYERS, ENC_KERNEL_SIZE, ENC_DROPOUT, device)\r\n",
        "dec = Decoder(OUTPUT_DIM, EMB_DIM, HID_DIM, DEC_LAYERS, DEC_KERNEL_SIZE, DEC_DROPOUT, TRG_PAD_IDX, device)\r\n",
        "\r\n",
        "model = Seq2Seq(enc, dec).to(device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHfxWJ_gMxhU"
      },
      "source": [
        "We also define a function that will calculate the number of trainable parameters in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vPNjyGcPevW",
        "outputId": "1e03d84d-ac38-4506-b0df-9da3895fa203"
      },
      "source": [
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 37,351,685 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF2nVLu3NYcC"
      },
      "source": [
        "We define our optimizer, which we use to update our parameters in the training loop.\r\n",
        "\r\n",
        "Next, we define our loss function. The CrossEntropyLoss function calculates both the log softmax as well as the negative log-likelihood of our predictions.\r\n",
        "\r\n",
        "Our loss function calculates the average loss per token, however by passing the index of the <pad> token as the ignore_index argument we ignore the loss whenever the target token is a padding token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA11W1cGPgBi"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLQ8YNSuORJH"
      },
      "source": [
        "Next, we'll define our training loop.\r\n",
        "\r\n",
        "First, we'll set the model into \"training mode\" with model.train(). This will turn on dropout and then iterate through our data iterator.\r\n",
        "\r\n",
        "Consider we have a target sequence, trg, of something like [\\<sos>, s1, s2, s3, \\<eos>]. We want our decoder to predict what the next item in the predicted target sequence should be, given the previously predicted target tokens. So, we input a sequence of [\\<sos>, s1, s2, s3] by slicing of \\<eos> token (which is trg[:,:-1]) and want our decoder to predict [s1, s2, s3, <eos>] (which is trg[:,1:]).\r\n",
        "\r\n",
        "Thus, we input trg[:,:-1] and use the predicted target with trg[:,1:] to calculate our losses.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVexyPAPPiPO"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    for i, batch in enumerate(iterator):\r\n",
        "        \r\n",
        "        src = batch.src\r\n",
        "        trg = batch.trg\r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        output, _ = model(src, trg[:,:-1])\r\n",
        "        \r\n",
        "        #output = [batch size, trg len - 1, output dim]\r\n",
        "        #trg = [batch size, trg len]\r\n",
        "        \r\n",
        "        output_dim = output.shape[-1]\r\n",
        "        \r\n",
        "        output = output.contiguous().view(-1, output_dim)\r\n",
        "        trg = trg[:,1:].contiguous().view(-1)\r\n",
        "        \r\n",
        "        #output = [batch size * trg len - 1, output dim]\r\n",
        "        #trg = [batch size * trg len - 1]\r\n",
        "        \r\n",
        "        loss = criterion(output, trg)\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "        \r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "        \r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxb55k2_d-Hz"
      },
      "source": [
        "\r\n",
        "Our evaluation loop is similar to our training loop, however as we aren't updating any parameters we don't need to pass an optimizer or a clip value.\r\n",
        "\r\n",
        "We must remember to set the model to evaluation mode with model.eval(). This will turn off dropout.\r\n",
        "\r\n",
        "We use the with torch.no_grad() block to ensure no gradients are calculated within the block. This reduces memory consumption and speeds things up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-w9g5kZPjhS"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for i, batch in enumerate(iterator):\r\n",
        "\r\n",
        "            src = batch.src\r\n",
        "            trg = batch.trg\r\n",
        "\r\n",
        "            output, _ = model(src, trg[:,:-1])\r\n",
        "        \r\n",
        "            #output = [batch size, trg len - 1, output dim]\r\n",
        "            #trg = [batch size, trg len]\r\n",
        "\r\n",
        "            output_dim = output.shape[-1]\r\n",
        "            \r\n",
        "            output = output.contiguous().view(-1, output_dim)\r\n",
        "            trg = trg[:,1:].contiguous().view(-1)\r\n",
        "\r\n",
        "            #output = [batch size * trg len - 1, output dim]\r\n",
        "            #trg = [batch size * trg len - 1]\r\n",
        "            \r\n",
        "            loss = criterion(output, trg)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b4m7DEGeLGw"
      },
      "source": [
        "Next, we'll create a function that we'll use to tell us how long an epoch takes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhPAu069Pk20"
      },
      "source": [
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZVc3DxSeRsQ"
      },
      "source": [
        "We can finally start training our model!\r\n",
        "\r\n",
        "At each epoch, we'll be checking if our model has achieved the best validation loss so far. If it has, we'll update our best validation loss and save the parameters of our model (called state_dict in PyTorch). Then, when we come to test our model, we'll use the saved parameters used to achieve the best validation loss.\r\n",
        "\r\n",
        "We'll be printing out both the loss and the perplexity at each epoch. It is easier to see a change in perplexity than a change in loss as the numbers are much bigger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPUxl1tMPmVg",
        "outputId": "4d2daefc-6e73-4e82-d429-5bfeb6ad8518"
      },
      "source": [
        "N_EPOCHS = 10\r\n",
        "CLIP = 0.01\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "    \r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\r\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    end_time = time.time()\r\n",
        "    \r\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "    \r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'tut5-model.pt')\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 1m 14s\n",
            "\tTrain Loss: 4.209 | Train PPL:  67.299\n",
            "\t Val. Loss: 3.017 |  Val. PPL:  20.431\n",
            "Epoch: 02 | Time: 1m 15s\n",
            "\tTrain Loss: 3.035 | Train PPL:  20.792\n",
            "\t Val. Loss: 2.388 |  Val. PPL:  10.893\n",
            "Epoch: 03 | Time: 1m 15s\n",
            "\tTrain Loss: 2.609 | Train PPL:  13.583\n",
            "\t Val. Loss: 2.132 |  Val. PPL:   8.433\n",
            "Epoch: 04 | Time: 1m 15s\n",
            "\tTrain Loss: 2.376 | Train PPL:  10.761\n",
            "\t Val. Loss: 2.004 |  Val. PPL:   7.415\n",
            "Epoch: 05 | Time: 1m 15s\n",
            "\tTrain Loss: 2.217 | Train PPL:   9.175\n",
            "\t Val. Loss: 1.911 |  Val. PPL:   6.758\n",
            "Epoch: 06 | Time: 1m 15s\n",
            "\tTrain Loss: 2.096 | Train PPL:   8.137\n",
            "\t Val. Loss: 1.859 |  Val. PPL:   6.416\n",
            "Epoch: 07 | Time: 1m 15s\n",
            "\tTrain Loss: 2.015 | Train PPL:   7.502\n",
            "\t Val. Loss: 1.810 |  Val. PPL:   6.111\n",
            "Epoch: 08 | Time: 1m 15s\n",
            "\tTrain Loss: 1.937 | Train PPL:   6.938\n",
            "\t Val. Loss: 1.784 |  Val. PPL:   5.952\n",
            "Epoch: 09 | Time: 1m 15s\n",
            "\tTrain Loss: 1.877 | Train PPL:   6.533\n",
            "\t Val. Loss: 1.769 |  Val. PPL:   5.863\n",
            "Epoch: 10 | Time: 1m 15s\n",
            "\tTrain Loss: 1.819 | Train PPL:   6.168\n",
            "\t Val. Loss: 1.737 |  Val. PPL:   5.680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luQHhZNkgAWu"
      },
      "source": [
        "We'll load the parameters (state_dict) that gave our model the best validation loss and run it the model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN-GkjB7Pn7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0106bef5-f009-48e1-e43d-a9820fa22f41"
      },
      "source": [
        "model.load_state_dict(torch.load('tut5-model.pt'))\r\n",
        "\r\n",
        "test_loss = evaluate(model, test_iterator, criterion)\r\n",
        "\r\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 1.798 | Test PPL:   6.035 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K6XatBggF_h"
      },
      "source": [
        "# Inference\r\n",
        "\r\n",
        "Now we can use our trained model to generate translations. Following are the steps that we taken during inference:\r\n",
        "- Firstly, ensure our model is in evaluation mode, which it should \"always\" be for inference\r\n",
        "- When a new unseen sentence is passed, we first convert that to lower case and tokenize the sentence\r\n",
        "- append the \\<sos> and \\<eos> tokens\r\n",
        "- map the tokens to their indexes i.e corresponding integer representation fron vocab\r\n",
        "- convert it to a tensor and use unsqueeze operation to add a batch dimension\r\n",
        "- feed the source sentence into the encoder using torch.no_grad() block to ensure no gradients are calculated within the block to reduce memory consumption and speed things up.\r\n",
        "- create a list to hold the output sentence, initialized with an \\<sos> token\r\n",
        "- while we have not hit a maximum length\r\n",
        "    - convert the current output sentence prediction into a tensor with a batch dimension\r\n",
        "    - place the current output and the two encoder outputs into the decoder\r\n",
        "    - get next output token prediction from decoder\r\n",
        "    - add prediction to current output sentence prediction\r\n",
        "    - break if the prediction was an <eos> token\r\n",
        "- convert the output sentence from indexes to tokens\r\n",
        "- return the output sentence (with the <sos> token removed) and the attention from the last layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MGwOb3qPrS4"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "        \r\n",
        "    if isinstance(sentence, str):\r\n",
        "        nlp = spacy.load('de')\r\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\r\n",
        "    else:\r\n",
        "        tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\r\n",
        "        \r\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\r\n",
        "\r\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        encoder_conved, encoder_combined = model.encoder(src_tensor)\r\n",
        "\r\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\r\n",
        "\r\n",
        "    for i in range(max_len):\r\n",
        "\r\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\r\n",
        "\r\n",
        "        with torch.no_grad():\r\n",
        "            output, attention = model.decoder(trg_tensor, encoder_conved, encoder_combined)\r\n",
        "        \r\n",
        "        pred_token = output.argmax(2)[:,-1].item()\r\n",
        "        \r\n",
        "        trg_indexes.append(pred_token)\r\n",
        "\r\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\r\n",
        "            break\r\n",
        "    \r\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\r\n",
        "    \r\n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To_E_M31k6Hn"
      },
      "source": [
        "\r\n",
        "Next, we'll make a function that displays the model's attention over the source sentence for each input during each decoder step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2ApPvr9PtgK"
      },
      "source": [
        "def display_attention(sentence, translation, attention):\r\n",
        "    \r\n",
        "    fig = plt.figure(figsize=(10,10))\r\n",
        "    ax = fig.add_subplot(111)\r\n",
        "        \r\n",
        "    attention = attention.squeeze(0).cpu().detach().numpy()\r\n",
        "    \r\n",
        "    cax = ax.matshow(attention, cmap='bone')\r\n",
        "   \r\n",
        "    ax.tick_params(labelsize=15)\r\n",
        "    ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \r\n",
        "                       rotation=45)\r\n",
        "    ax.set_yticklabels(['']+translation)\r\n",
        "\r\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "\r\n",
        "    plt.show()\r\n",
        "    plt.close()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DjVmwFrlQ55"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ48fLMsPu-1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c75ff280-ba5b-40e2-f086-1df4a01169d4"
      },
      "source": [
        "example_idx = 2\r\n",
        "\r\n",
        "src = vars(train_data.examples[example_idx])['src']\r\n",
        "trg = vars(train_data.examples[example_idx])['trg']\r\n",
        "\r\n",
        "print(f'src = {src}')\r\n",
        "print(f'trg = {trg}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['ein', 'kleines', 'mädchen', 'klettert', 'in', 'ein', 'spielhaus', 'aus', 'holz', '.']\n",
            "trg = ['a', 'little', 'girl', 'climbing', 'into', 'a', 'wooden', 'playhouse', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULOvdnc1PwG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774768cf-a6ad-46ee-de21-f215d3a1c423"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "\r\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['a', 'little', 'girl', 'climbing', 'in', 'a', 'playhouse', 'made', 'of', 'wood', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bU8kjg4PxTq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "a9729c70-26e0-469c-898a-b5e1384424b0"
      },
      "source": [
        "display_attention(src, translation, attention)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADickZvsPyhI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f79b9a41-3ddc-4053-cc2f-c0e952d24a97"
      },
      "source": [
        "example_idx = 2\r\n",
        "\r\n",
        "src = vars(valid_data.examples[example_idx])['src']\r\n",
        "trg = vars(valid_data.examples[example_idx])['trg']\r\n",
        "\r\n",
        "print(f'src = {src}')\r\n",
        "print(f'trg = {trg}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['ein', 'junge', 'mit', 'kopfhörern', 'sitzt', 'auf', 'den', 'schultern', 'einer', 'frau', '.']\n",
            "trg = ['a', 'boy', 'wearing', 'headphones', 'sits', 'on', 'a', 'woman', \"'s\", 'shoulders', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkXuD77iP0f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06e13af3-2a05-4b70-d031-a8dbf974d3c7"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "\r\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['a', 'boy', 'with', 'headphones', 'sits', 'on', 'the', 'shoulders', 'of', 'a', 'woman', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uphiAwagP1ks",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "outputId": "f913d6bc-b865-4c0b-9edb-f4e8eec51d49"
      },
      "source": [
        "display_attention(src, translation, attention)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndDCH8m6P23M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d07248-7809-404a-a014-71091c877526"
      },
      "source": [
        "example_idx = 9\r\n",
        "\r\n",
        "src = vars(test_data.examples[example_idx])['src']\r\n",
        "trg = vars(test_data.examples[example_idx])['trg']\r\n",
        "\r\n",
        "print(f'src = {src}')\r\n",
        "print(f'trg = {trg}')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['ein', 'mann', 'in', 'einer', 'weste', 'sitzt', 'auf', 'einem', 'stuhl', 'und', 'hält', 'magazine', '.']\n",
            "trg = ['a', 'man', 'in', 'a', 'vest', 'is', 'sitting', 'in', 'a', 'chair', 'and', 'holding', 'magazines', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj_clFYtP4E0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb765cec-8352-4e8f-84aa-06e4b8158248"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "\r\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['a', 'man', 'in', 'a', 'vest', 'is', 'sitting', 'on', 'a', 'chair', 'holding', 'a', '<unk>', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVkG0MkOP5QQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "outputId": "02ec45a9-62a4-4a2d-e1de-39703c63552c"
      },
      "source": [
        "display_attention(src, translation, attention)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LSL9J_Xm8Cs"
      },
      "source": [
        "# BLEU Score\r\n",
        "\r\n",
        "The Bilingual Evaluation Understudy Score, or BLEU for short is a method for automatic evaluation of machine translation. BLEU is a score for comparing/evaluating a candidate translation (translated sentence) of text to one or more reference translation (ground truth). \r\n",
        "It is based on \"text string matches\" i.e it quantifies how good a machine translation by computing a similarity score based on ngram precision.\r\n",
        "\r\n",
        "BLEU score can also be used to evalutate a wide range of text generation NLP tasks like language generation, image caption generation, text summarization etc.\r\n",
        "\r\n",
        "Few benefits of BLEU score:\r\n",
        "  - Quick and inexpensive to calculate\r\n",
        "  - easy to understand\r\n",
        "  - language independent\r\n",
        "\r\n",
        "\r\n",
        "BLEU metrics ranges from 0 to 1. The higher the BLEU Score the better.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq0kiimuWRdT"
      },
      "source": [
        "\r\n",
        "from torchtext.data.metrics import bleu_score\r\n",
        "\r\n",
        "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\r\n",
        "    \r\n",
        "    trgs = []\r\n",
        "    pred_trgs = []\r\n",
        "    \r\n",
        "    for datum in data:\r\n",
        "        \r\n",
        "        src = vars(datum)['src']\r\n",
        "        trg = vars(datum)['trg']\r\n",
        "        \r\n",
        "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\r\n",
        "        \r\n",
        "        #cut off <eos> token\r\n",
        "        pred_trg = pred_trg[:-1]\r\n",
        "        \r\n",
        "        pred_trgs.append(pred_trg)\r\n",
        "        trgs.append([trg])\r\n",
        "        \r\n",
        "    return bleu_score(pred_trgs, trgs)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jm_nA9-5zFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f1da31-fc57-4d95-8602-85a80bc42b40"
      },
      "source": [
        "bleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\r\n",
        "\r\n",
        "print(f'BLEU score = {bleu_score*100:.2f}')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU score = 34.41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPot8SsY6Qzk"
      },
      "source": [
        "# Conclusion\r\n",
        "\r\n",
        "Compared to RNN models convolution models have two advantages. \r\n",
        "- First, it runs faster because convolution can be performed in parallel. By contrast, RNN needs to wait for the value of the previous timesteps to be computed.\r\n",
        "- Second, it captures dependencies of different lengths between the words easily. In a group of stacked CNN layers, the bottom layers captures closer dependencies while the top layers extract longer (complex) dependencies  between words.\r\n",
        "\r\n",
        "Having said that when comparing RNN vs CNN, both are commonplace in the field of Deep Learning. Each architecture has advantages and disadvantages that are dependent upon the type of data that is being modeled.\r\n",
        "\r\n",
        "***From the abstract of the paper, the authors claim to outperform the accuracy of deep LSTMs in WMT’14 English-German and WMT’14 English-French translation at an order of magnitude faster speed, both on GPU and CPU*.**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MopmMhG1LQXw"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}