{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Translate_English_to_Python_Code_using_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e65dec0b3003457b9b22c6d751f0376a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_281a28fd3fca44e3be93dede28d30225",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8d19fae8f4474f0ab7baf9571debe929",
              "IPY_MODEL_33ce7468e05b4a7bbeeb99aa28731790"
            ]
          }
        },
        "281a28fd3fca44e3be93dede28d30225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d19fae8f4474f0ab7baf9571debe929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_43a4e6724cda49bfb744f93ee16ffbf8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d595c4f416f243a1b12046af4969bc22"
          }
        },
        "33ce7468e05b4a7bbeeb99aa28731790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3de2f8cefa254aa0bc1609aad1213c98",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6232/? [14:23&lt;00:00,  7.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a694f5a066e344c6a9f4402c58f96c00"
          }
        },
        "43a4e6724cda49bfb744f93ee16ffbf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d595c4f416f243a1b12046af4969bc22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3de2f8cefa254aa0bc1609aad1213c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a694f5a066e344c6a9f4402c58f96c00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjufbYt4gLtk",
        "outputId": "2e8ea1fe-fa34-4f95-ae9f-c994262629fd"
      },
      "source": [
        "%%bash\n",
        "python -m spacy download en\n",
        "pip install python_minifier autopep8"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.1.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Requirement already satisfied: python_minifier in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: autopep8 in /usr/local/lib/python3.7/dist-packages (1.5.6)\n",
            "Requirement already satisfied: pycodestyle>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from autopep8) (2.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from autopep8) (0.10.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6tgTH6CaVCC"
      },
      "source": [
        "### Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgTxHeAvl3Er"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator, LabelField, TabularDataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import python_minifier\n",
        "import io\n",
        "import tokenize\n",
        "import re\n",
        "import autopep8\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu7oVMDHsGUB"
      },
      "source": [
        "# %load_ext autoreload\n",
        "# %autoreload 2\n",
        "\n",
        "# %load_ext google.colab.data_table"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlXlmzyGgvdF"
      },
      "source": [
        "## Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxOosFiusFEq"
      },
      "source": [
        "code_list = [[]]\n",
        "filename = '/content/data_cleaned_tabs_only.txt'\n",
        "#with open(filename) as f:\n",
        "\n",
        "with open(filename) as f:\n",
        "  #my_dict = {\"description\":[],\"code\":[]}\n",
        "  for line in f:\n",
        "    if line.startswith('#'):\n",
        "      comment = line.split('\\n#')\n",
        "      if code_list[-1] != []:\n",
        "        # we are in a new block\n",
        "        code_list.append(comment)\n",
        "    else:\n",
        "      stripped_line = line#.strip()\n",
        "      if stripped_line:\n",
        "        code_list[-1].append(stripped_line)       "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPDtu92GtTDz"
      },
      "source": [
        "raw_data_dict = {'Description' : [re.sub(r\"^#(\\d)*\",'',x[0]).strip() for x in code_list], 'Code': [''.join(x[1:]) for x in code_list]}\n",
        "df = pd.DataFrame(raw_data_dict, columns=[\"Description\", \"Code\"])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "joZWm0JTtTBP",
        "outputId": "ad868f5f-7324-47fc-8675-898e3a6d9423"
      },
      "source": [
        "df['Description'][1617]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'two numbers are anagram'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lJWK5om1tS-o",
        "outputId": "7212037f-8028-4c48-ca08-9bcbfd5f4c89"
      },
      "source": [
        "df['Code'][1617]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n\\nfrom collections import Counter\\n\\ndef checkAnagram(num1, num2):\\n\\tbin1=bin(num1)[2:]\\n\\tbin2=bin(num2)[2:]\\n\\n\\tzeros=abs(len(bin1) - len(bin2))\\n\\tif (len(bin1) > len(bin2)):\\n\\t\\t bin2=zeros * '0' + bin2\\n\\telse:\\n\\t\\t bin1=zeros * '0' + bin1\\n\\n\\tdict1=Counter(bin1)\\n\\tdict2=Counter(bin2)\\n\\n\\n\\n\\tif dict1 == dict2:\\n\\t\\t print('Yes')\\n\\telse:\\n\\t\\t print('No')\\n\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "EELw2XAisFB9",
        "outputId": "c20c8dfd-1db0-40e5-d2a4-a6f392abd794"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add two user provid...</td>\n",
              "      <td>\\n\\ndef add_two_numbers(num1, num2):\\n\\tsum = ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a program to find and print the largest ...</td>\n",
              "      <td>\\n\\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a program to find and print the smallest...</td>\n",
              "      <td>\\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;=...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Write a python function to merge two given lis...</td>\n",
              "      <td>\\n\\ndef merge_lists(l1, l2):\\n\\treturn l1 + l2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Description                                               Code\n",
              "0                                                     num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...\n",
              "1  write a python function to add two user provid...  \\n\\ndef add_two_numbers(num1, num2):\\n\\tsum = ...\n",
              "2  write a program to find and print the largest ...  \\n\\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 ...\n",
              "3  write a program to find and print the smallest...  \\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <=...\n",
              "4  Write a python function to merge two given lis...  \\n\\ndef merge_lists(l1, l2):\\n\\treturn l1 + l2..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f9_1op7uKPe"
      },
      "source": [
        "def fix_py(code):\n",
        "  '''\n",
        "  Fixing the raw code obtained by using autopep8 library\n",
        "  '''\n",
        "  code = autopep8.fix_code(code, options={'ignore': ['E402']})\n",
        "  io_obj = io.StringIO(code)\n",
        "  res = []\n",
        "  prev_toktype = tokenize.INDENT\n",
        "  last_lineno = -1\n",
        "  last_col = 0\n",
        "  for tok in tokenize.generate_tokens(io_obj.readline):\n",
        "      token_type = tok[0]\n",
        "      token_string = tok[1]\n",
        "      start_line, start_col = tok[2]\n",
        "      end_line, end_col = tok[3]\n",
        "      ltext = tok[4]\n",
        "      if start_line > last_lineno:\n",
        "          last_col = 0\n",
        "      if start_col > last_col:\n",
        "          res.append(\" \" * (start_col - last_col))\n",
        "      if token_type == tokenize.COMMENT:\n",
        "          pass\n",
        "      elif token_type == tokenize.STRING:\n",
        "          if prev_toktype != tokenize.INDENT:\n",
        "              if prev_toktype != tokenize.NEWLINE:\n",
        "                  if start_col > 0:\n",
        "                      res.append(token_string)\n",
        "      else:\n",
        "          res.append(token_string)\n",
        "      prev_toktype = token_type\n",
        "      last_col = end_col\n",
        "      last_lineno = end_line\n",
        "  res = ['\\t' if a == '    ' else a for a in res]\n",
        "  return res"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "e65dec0b3003457b9b22c6d751f0376a",
            "281a28fd3fca44e3be93dede28d30225",
            "8d19fae8f4474f0ab7baf9571debe929",
            "33ce7468e05b4a7bbeeb99aa28731790",
            "43a4e6724cda49bfb744f93ee16ffbf8",
            "d595c4f416f243a1b12046af4969bc22",
            "3de2f8cefa254aa0bc1609aad1213c98",
            "a694f5a066e344c6a9f4402c58f96c00"
          ]
        },
        "id": "NDJt9Rjyt0Cy",
        "outputId": "c6a190b2-cd58-41e5-de9a-01b51f4d91b0"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "df_final = pd.DataFrame()\n",
        "for _, row in tqdm(df.iterrows()):\n",
        "    code = fix_py(code=row['Code'])\n",
        "    \n",
        "    if code:\n",
        "        row['Code'] = ''.join(a for a in code)\n",
        "        df_final = df_final.append(row)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e65dec0b3003457b9b22c6d751f0376a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "0bRf5sh8tz_z",
        "outputId": "38cd1d27-9432-427b-9419-5b1da047363e"
      },
      "source": [
        "df_final.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n\\ndef add_two_numbers(num1, num2):\\n\\tsum = ...</td>\n",
              "      <td>write a python function to add two user provid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\n\\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 ...</td>\n",
              "      <td>write a program to find and print the largest ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;=...</td>\n",
              "      <td>write a program to find and print the smallest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\n\\ndef merge_lists(l1, l2):\\n\\treturn l1 + l2\\n</td>\n",
              "      <td>Write a python function to merge two given lis...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Code                                        Description\n",
              "0  num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...                                                   \n",
              "1  \\n\\ndef add_two_numbers(num1, num2):\\n\\tsum = ...  write a python function to add two user provid...\n",
              "2  \\n\\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 ...  write a program to find and print the largest ...\n",
              "3  \\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <=...  write a program to find and print the smallest...\n",
              "4   \\n\\ndef merge_lists(l1, l2):\\n\\treturn l1 + l2\\n  Write a python function to merge two given lis..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBhjzjA14GiU"
      },
      "source": [
        "Dropping all NaN values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX1ZrioOtz9P"
      },
      "source": [
        "df_final.dropna(subset = [\"Code\"], inplace=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK55_3tHyJqt"
      },
      "source": [
        "df_final=df_final[['Description', 'Code']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MckNJHCB52JD"
      },
      "source": [
        "Replacing all tabs, new line and space characters with TAB, NL, SPC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQB9eJv5tz4F"
      },
      "source": [
        "df_final['Code']=df_final['Code'].str.replace('\\t', '<TAB>')\n",
        "df_final['Code']=df_final['Code'].str.replace('\\n', '<NL>')\n",
        "df_final['Code']=df_final['Code'].str.replace(' ', '<SPC>')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "TSRVzEGuyPb1",
        "outputId": "c891eeb7-7e8a-499b-942e-37c31e754468"
      },
      "source": [
        "df_final[df_final['Description'].str.contains('function')]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add two user provid...</td>\n",
              "      <td>\\n\\ndef add_two_numbers(num1, num2):\\n\\tsum = ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Write a python function to merge two given lis...</td>\n",
              "      <td>\\n\\ndef merge_lists(l1, l2):\\n\\treturn l1 + l2\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Write a python function that prints the factor...</td>\n",
              "      <td>\\n\\ndef print_factors(x):\\n\\tprint(f\"The facto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Write a python function to print whether a num...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Write a python function to print powers of 2, ...</td>\n",
              "      <td>\\n\\ndef two_power(terms):\\n\\tresult = list(map...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6103</th>\n",
              "      <td>Write a function to compute 5/0 and use try/ex...</td>\n",
              "      <td>def throws():\\n\\treturn 5 / 0\\n\\n\\ntry:\\n\\tthr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6133</th>\n",
              "      <td>write a binary search function which searches ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6134</th>\n",
              "      <td>The function should return the index of elemen...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6136</th>\n",
              "      <td>write a binary search function which searches ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6137</th>\n",
              "      <td>The function should return the index of elemen...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1833 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Description                                               Code\n",
              "1     write a python function to add two user provid...  \\n\\ndef add_two_numbers(num1, num2):\\n\\tsum = ...\n",
              "4     Write a python function to merge two given lis...   \\n\\ndef merge_lists(l1, l2):\\n\\treturn l1 + l2\\n\n",
              "6     Write a python function that prints the factor...  \\n\\ndef print_factors(x):\\n\\tprint(f\"The facto...\n",
              "8     Write a python function to print whether a num...                                                   \n",
              "11    Write a python function to print powers of 2, ...  \\n\\ndef two_power(terms):\\n\\tresult = list(map...\n",
              "...                                                 ...                                                ...\n",
              "6103  Write a function to compute 5/0 and use try/ex...  def throws():\\n\\treturn 5 / 0\\n\\n\\ntry:\\n\\tthr...\n",
              "6133  write a binary search function which searches ...                                                   \n",
              "6134  The function should return the index of elemen...                                                   \n",
              "6136  write a binary search function which searches ...                                                   \n",
              "6137  The function should return the index of elemen...                                                   \n",
              "\n",
              "[1833 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFH5CU3q6FIU"
      },
      "source": [
        "Getting all the lengths of each code, and limiting the max length to 2000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBRlJfZe078I",
        "outputId": "cbe976d7-8cd3-429d-e5d9-0974f897fef3"
      },
      "source": [
        "for key, value in df_final['Code'].iteritems():\n",
        "    if int(len(df_final['Code'][key])) > 2000 :\n",
        "\n",
        "      print(key, int(len(df_final['Code'][key])))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "813 2015\n",
            "1718 2521\n",
            "4882 5069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf1bz6qO3DgH",
        "outputId": "6fc778ed-a5a5-4b2c-8bbe-848bcdd2d2e4"
      },
      "source": [
        "df_final['len'] = df_final['Code'].str.len()\n",
        "df_final = df_final.drop(df_final[df_final['len'] == 0].index)\n",
        "df_final = df_final[df_final['len'] < 2000]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E30BzWMF6cd1"
      },
      "source": [
        "Sorting the codes based on the code length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXVZUQCo3K0D"
      },
      "source": [
        "df_final = df_final.sort_values(by='Description', key=lambda x:x.str.len())"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu-G7PYS6noX"
      },
      "source": [
        "Checking for '\\t' if it exits still"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "DvyX-6EUyeAx",
        "outputId": "60b0367a-840a-4221-cae3-bfc52bd5fc3d"
      },
      "source": [
        "df_final[df_final['Code'].str.contains('\\t')]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Code</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4793</th>\n",
              "      <td>80]</td>\n",
              "      <td>\\n\\na = [10, 20, 30, 20, 10, 50, 60, 40, 80, 5...</td>\n",
              "      <td>193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1882</th>\n",
              "      <td>s=''</td>\n",
              "      <td>for i in test_list:\\n\\ts = ''\\n\\tfor j in i:\\n...</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6135</th>\n",
              "      <td>list.</td>\n",
              "      <td>import math\\n\\n\\ndef bin_search(li, element):\\...</td>\n",
              "      <td>431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1937</th>\n",
              "      <td>of 4.</td>\n",
              "      <td>def reverse_string(str1):\\n\\tif len(str1) % 4 ...</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6055</th>\n",
              "      <td>keys.</td>\n",
              "      <td>def printDict():\\n\\td = dict()\\n\\tfor i in ran...</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1446</th>\n",
              "      <td>Write a Python function to find the N-th numbe...</td>\n",
              "      <td>def nth_sq_and_cube(N):\\n\\tR = N**6\\n\\treturn R\\n</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2128</th>\n",
              "      <td>write a Python function that returns the deter...</td>\n",
              "      <td>def determinant(A):\\n\\tif len(A) == 1:\\n      ...</td>\n",
              "      <td>409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3006</th>\n",
              "      <td>write a python program to count how many times...</td>\n",
              "      <td>string = 'The quick brown fox jumps over the l...</td>\n",
              "      <td>220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4404</th>\n",
              "      <td>Write a Python function to find the N-th numbe...</td>\n",
              "      <td>def nth_sq_and_cube(N):\\n\\tR = N**6\\n\\treturn R\\n</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5657</th>\n",
              "      <td>8 write a python function to accept a key, val...</td>\n",
              "      <td>\\n\\ndef create_dictionary(key, value):\\n\\tretu...</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3116 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Description  ...  len\n",
              "4793                                                80]  ...  193\n",
              "1882                                               s=''  ...   84\n",
              "6135                                              list.  ...  431\n",
              "1937                                              of 4.  ...  102\n",
              "6055                                              keys.  ...   83\n",
              "...                                                 ...  ...  ...\n",
              "1446  Write a Python function to find the N-th numbe...  ...   44\n",
              "2128  write a Python function that returns the deter...  ...  409\n",
              "3006  write a python program to count how many times...  ...  220\n",
              "4404  Write a Python function to find the N-th numbe...  ...   44\n",
              "5657  8 write a python function to accept a key, val...  ...   63\n",
              "\n",
              "[3116 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTRFcdlz8A08"
      },
      "source": [
        "del df_final['len']"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "QXi-yEjrtz11",
        "outputId": "7400f444-b0dd-4f0a-95a6-7fc957be7ef9"
      },
      "source": [
        "df_final"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5199</th>\n",
              "      <td>it</td>\n",
              "      <td>li = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\\nevenNumb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5027</th>\n",
              "      <td>or</td>\n",
              "      <td>x = [[[value1]]]  \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>or</td>\n",
              "      <td>x = [[[value1]]]  \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4793</th>\n",
              "      <td>80]</td>\n",
              "      <td>\\n\\na = [10, 20, 30, 20, 10, 50, 60, 40, 80, 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4414</th>\n",
              "      <td>Write a Python program to print euclidean dist...</td>\n",
              "      <td>import numpy as np\\na = np.array([78, 84, 87, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4404</th>\n",
              "      <td>Write a Python function to find the N-th numbe...</td>\n",
              "      <td>def nth_sq_and_cube(N):\\n\\tR = N**6\\n\\treturn R\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5950</th>\n",
              "      <td>write Python code to demonstrate to remove the...</td>\n",
              "      <td>\\n\\nini_tuple = [('b', 100), ('c', 200), ('c',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5657</th>\n",
              "      <td>8 write a python function to accept a key, val...</td>\n",
              "      <td>\\n\\ndef create_dictionary(key, value):\\n\\tretu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1787</th>\n",
              "      <td>35 Write a python program to remove duplicate ...</td>\n",
              "      <td>str1 = \"Good bye bye world world\"\\nl = str1.sp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4429 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Description                                               Code\n",
              "0                                                        num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...\n",
              "5199                                                 it  li = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\\nevenNumb...\n",
              "5027                                                 or                               x = [[[value1]]]  \\n\n",
              "1255                                                 or                               x = [[[value1]]]  \\n\n",
              "4793                                                80]  \\n\\na = [10, 20, 30, 20, 10, 50, 60, 40, 80, 5...\n",
              "...                                                 ...                                                ...\n",
              "4414  Write a Python program to print euclidean dist...  import numpy as np\\na = np.array([78, 84, 87, ...\n",
              "4404  Write a Python function to find the N-th numbe...  def nth_sq_and_cube(N):\\n\\tR = N**6\\n\\treturn R\\n\n",
              "5950  write Python code to demonstrate to remove the...  \\n\\nini_tuple = [('b', 100), ('c', 200), ('c',...\n",
              "5657  8 write a python function to accept a key, val...  \\n\\ndef create_dictionary(key, value):\\n\\tretu...\n",
              "1787  35 Write a python program to remove duplicate ...  str1 = \"Good bye bye world world\"\\nl = str1.sp...\n",
              "\n",
              "[4429 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EESb0w7569ft"
      },
      "source": [
        "### Splitting the dataset into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caV5Yo_B680u"
      },
      "source": [
        "train, test = train_test_split(df_final, test_size=0.2, random_state=42, shuffle=True)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww4DLXr4tzy-"
      },
      "source": [
        "train.to_csv('train.tsv', index=False, sep='\\t')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5TDtelY7rgp"
      },
      "source": [
        "test.to_csv('test.tsv', index=False, sep='\\t')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKFtuzKVaeRv"
      },
      "source": [
        "### Loading train and valid tab separated files as dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEcJEKoVViR1"
      },
      "source": [
        "train_df = pd.read_csv('/content/train.tsv', sep='\\t')\n",
        "test_df = pd.read_csv('/content/test.tsv', sep='\\t')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "VSK2ztJfjrOW",
        "outputId": "adebba9b-c07d-45f2-b42d-b78f143b1af9"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Concatenation of two List</td>\n",
              "      <td>my_list1 = [4, 3, 2, 9, 10, 44, 1]\\nmy_list2 =...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Calculate the length of dictionary</td>\n",
              "      <td>thisdict = {\\n\\t\"brand\": \"Ford\",\\n\\t\"model\": \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a python function to calculate age given...</td>\n",
              "      <td>\\n\\nfrom datetime import date\\n\\n\\ndef calcula...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write Python program to illustrate  enumerate ...</td>\n",
              "      <td>l1 = [\"eat\", \"sleep\", \"repeat\"]\\n\\n\\nfor count...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>is odd</td>\n",
              "      <td>def add_even_odd_list(l1: list, l2: list) -&gt; l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Description                                               Code\n",
              "0                          Concatenation of two List  my_list1 = [4, 3, 2, 9, 10, 44, 1]\\nmy_list2 =...\n",
              "1                 Calculate the length of dictionary  thisdict = {\\n\\t\"brand\": \"Ford\",\\n\\t\"model\": \"...\n",
              "2  write a python function to calculate age given...  \\n\\nfrom datetime import date\\n\\n\\ndef calcula...\n",
              "3  write Python program to illustrate  enumerate ...  l1 = [\"eat\", \"sleep\", \"repeat\"]\\n\\n\\nfor count...\n",
              "4                                             is odd  def add_even_odd_list(l1: list, l2: list) -> l..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "J_86lGtVVy-b",
        "outputId": "e699b3b2-63f8-4ae8-8e26-5562109fdb4e"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Write a python function to remove duplicates f...</td>\n",
              "      <td>\\n\\ndef remove_duplicates(lista):\\n\\tlista2 = ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>join using a - hyphen.</td>\n",
              "      <td>def word_join(s):\\n\\twords = s.split(' ')\\n\\tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a function to find out the second maximu...</td>\n",
              "      <td>def find_second_maximum(lst):\\n\\tmax = float('...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Concatenation of two List</td>\n",
              "      <td>my_list1 = [4, 3, 2, 9, 10, 44, 1]\\nmy_list2 =...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>date of birth</td>\n",
              "      <td>\\n\\ndef zodiac_sign(day, month):\\n\\n\\tif month...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Description                                               Code\n",
              "0  Write a python function to remove duplicates f...  \\n\\ndef remove_duplicates(lista):\\n\\tlista2 = ...\n",
              "1                             join using a - hyphen.  def word_join(s):\\n\\twords = s.split(' ')\\n\\tr...\n",
              "2  write a function to find out the second maximu...  def find_second_maximum(lst):\\n\\tmax = float('...\n",
              "3                          Concatenation of two List  my_list1 = [4, 3, 2, 9, 10, 44, 1]\\nmy_list2 =...\n",
              "4                                      date of birth  \\n\\ndef zodiac_sign(day, month):\\n\\n\\tif month..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVZCbOyO8UY4"
      },
      "source": [
        "Getting some info on daataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwMMe5CQCU5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8f5cd2-4ee9-4fbe-c9ea-b140501ab710"
      },
      "source": [
        "train_df.info()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3543 entries, 0 to 3542\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Description  3542 non-null   object\n",
            " 1   Code         3543 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 55.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF6y9cd-gbra",
        "outputId": "3edf82f0-3469-4234-c590-a05f28c1bee8"
      },
      "source": [
        "test_df.info()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 886 entries, 0 to 885\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Description  886 non-null    object\n",
            " 1   Code         886 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 14.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15wydnnsCpH0"
      },
      "source": [
        "spacy_en = spacy.load('en')\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAFyg19ChPtX"
      },
      "source": [
        "def tokenizerpy(source):\n",
        "  '''\n",
        "  Tokenizes and fixes python code\n",
        "  '''\n",
        "  source = autopep8.fix_code(source,\n",
        "                                options={'ignore': ['E402']})\n",
        "  io_obj = io.StringIO(source)\n",
        "  out = []\n",
        "  prev_toktype = tokenize.INDENT\n",
        "  last_lineno = -1\n",
        "  last_col = 0\n",
        "  for tok in tokenize.generate_tokens(io_obj.readline):\n",
        "      token_type = tok[0]\n",
        "      token_string = tok[1]\n",
        "      start_line, start_col = tok[2]\n",
        "      end_line, end_col = tok[3]\n",
        "      ltext = tok[4]\n",
        "      if start_line > last_lineno:\n",
        "          last_col = 0\n",
        "      if start_col > last_col:\n",
        "          out.append(\" \" * (start_col - last_col))\n",
        "      if token_type == tokenize.COMMENT:\n",
        "          pass\n",
        "      elif token_type == tokenize.STRING:\n",
        "          if prev_toktype != tokenize.INDENT:\n",
        "              if prev_toktype != tokenize.NEWLINE:\n",
        "                  if start_col > 0:\n",
        "                      out.append(token_string)\n",
        "      else:\n",
        "          out.append(token_string)\n",
        "      prev_toktype = token_type\n",
        "      last_col = end_col\n",
        "      last_lineno = end_line\n",
        "  out = ['\\t' if a == '    ' else a for a in out]\n",
        "  return out"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfEkZ1UtUCy8"
      },
      "source": [
        "def tokenize_py(code):\n",
        "    ''' Custom Python tokenizer that tokenizes python code '''\n",
        "    code = code.replace('<TAB>', '\\t')\n",
        "    tokens = tokenizerpy(code)\n",
        "    return tokens\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V90bbxan-NMC"
      },
      "source": [
        "### Setting up the field datatypes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60O0YZ8eCrLd"
      },
      "source": [
        "SRC = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_py, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = False, \n",
        "            batch_first = True)\n",
        "fields = [('Description', SRC),('Code',TRG)]\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN8mz9Ky-Qkl"
      },
      "source": [
        "### Creating the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TzuyiGaCstq"
      },
      "source": [
        "train_data, test_data = TabularDataset.splits(\n",
        "                                path = '',   \n",
        "                                train = 'train.tsv',\n",
        "                                test = 'test.tsv',\n",
        "                                skip_header = True,\n",
        "                                format = 'tsv',\n",
        "                                fields = fields)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZoPGBSerpdw",
        "outputId": "5e6f6217-a52d-45b2-eaa9-3c450bde0269"
      },
      "source": [
        "print(' '.join(_ for _ in vars(train_data.examples[1000])['Description']))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "write a python program uses else with for loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2PXYT9QNA7x",
        "outputId": "c8a56953-e306-4908-889d-12102038bd20"
      },
      "source": [
        "print(''.join(_ for _ in vars(train_data.examples[1000])['Code']))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seq = \"abcde\"\n",
            "for k in seq:\n",
            "\tif k == \"f\":\n",
            "\tbreak\n",
            "else:\n",
            "\tprint(\"f Not Found!\")\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F5RrYym9ucE"
      },
      "source": [
        "##Setting up the *device*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XONz6UrCwuh"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo450NiW9zZP"
      },
      "source": [
        "### Building the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fETHzIIyCu7p"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 1, max_size= 10000)\n",
        "TRG.build_vocab(train_data, min_freq = 1,max_size= 10000)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "159XEIRnO8Lu",
        "outputId": "d3997d96-fe54-45d5-fdc5-baedfcc041a9"
      },
      "source": [
        "len(SRC.vocab), len(TRG.vocab)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1714, 5750)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrN4jSvIsDr2"
      },
      "source": [
        "BATCH_SIZE = 24\n",
        "\n",
        "train_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda x: len(x.Description),\n",
        "    device = device)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACYg_NYe-ecE"
      },
      "source": [
        "### Saving the Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJJ2X-PF-dbd"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(SRC.vocab.stoi, tokens)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl5PV-xW-j4v"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE6JimgOCz-w"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]        \n",
        "        return output, attention"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LheiXWVFDEg"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 2000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        " \n",
        "            \n",
        "        return src"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZmeHfGhGzkN"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9w9xDUKL7LU"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWBMMF45MMNS"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr3Mg8OGN6ul"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 2000):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "            \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmhDkDR7krMu"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        # query, key, value\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zsZjSSWOSHc"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 2\n",
        "DEC_LAYERS = 2\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT,\n",
        "              device)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2AddGyH-7yL"
      },
      "source": [
        "## Training the Seq2Seq Model\n",
        "\n",
        "The rest of this session is very similar to the previous one.\n",
        "\n",
        "We initialise our parameters, encoder, decoder and seq2seq model (placing it on the GPU if we have one). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYVZYDVcOUGK"
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd0ePzj0OzLa",
        "outputId": "0d932a94-a4ae-4c61-c47c-3a461ef0ef57"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 7,048,310 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmZ0hyo8O0vE"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRtAM9Y4O2N2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f73c210-c3cc-4ca6-a2e4-ad9389e39214"
      },
      "source": [
        "model.apply(initialize_weights)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(1714, 256)\n",
              "    (pos_embedding): Embedding(2000, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tok_embedding): Embedding(5750, 256)\n",
              "    (pos_embedding): Embedding(2000, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=256, out_features=5750, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCrlEqSR_D0V"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEpApG3YO3ZE"
      },
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ5isdjp_Fxr"
      },
      "source": [
        "### Using CrossEntropyLoss as the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9Dy_wWrO46l"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TofBH_Ep_MHN"
      },
      "source": [
        "## Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycBBiEpuO6cG"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.Description\n",
        "        trg = batch.Code\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "                \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "            \n",
        "        loss = criterion(output, trg)\n",
        "        #loss = maskNLLLoss(output, trg,model.trg_pad_idx)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi3Ev8gaO79_"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.Description\n",
        "            trg = batch.Code\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "           \n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "            #loss = maskNLLLoss(output, trg,model.trg_pad_idx)\n",
        "\n",
        "            #loss,_ = maskNLLLoss(output, trg, mask)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDErvEuP_Sy7"
      },
      "source": [
        "Function to get the elapsed time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuB4JqQRO9Wg"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aax76Ie4O_Cr",
        "outputId": "ccd6ebf1-11f9-4e1a-a8ca-6b0b0be6af56"
      },
      "source": [
        "import time\n",
        "N_EPOCHS = 40\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, test_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 10s\n",
            "\tTrain Loss: 3.422 | Train PPL:  30.643\n",
            "\t Val. Loss: 2.405 |  Val. PPL:  11.077\n",
            "Epoch: 02 | Time: 0m 10s\n",
            "\tTrain Loss: 2.194 | Train PPL:   8.973\n",
            "\t Val. Loss: 2.075 |  Val. PPL:   7.968\n",
            "Epoch: 03 | Time: 0m 11s\n",
            "\tTrain Loss: 1.885 | Train PPL:   6.585\n",
            "\t Val. Loss: 1.882 |  Val. PPL:   6.569\n",
            "Epoch: 04 | Time: 0m 10s\n",
            "\tTrain Loss: 1.661 | Train PPL:   5.267\n",
            "\t Val. Loss: 1.733 |  Val. PPL:   5.658\n",
            "Epoch: 05 | Time: 0m 11s\n",
            "\tTrain Loss: 1.476 | Train PPL:   4.374\n",
            "\t Val. Loss: 1.633 |  Val. PPL:   5.118\n",
            "Epoch: 06 | Time: 0m 11s\n",
            "\tTrain Loss: 1.316 | Train PPL:   3.729\n",
            "\t Val. Loss: 1.543 |  Val. PPL:   4.681\n",
            "Epoch: 07 | Time: 0m 11s\n",
            "\tTrain Loss: 1.174 | Train PPL:   3.236\n",
            "\t Val. Loss: 1.466 |  Val. PPL:   4.333\n",
            "Epoch: 08 | Time: 0m 11s\n",
            "\tTrain Loss: 1.057 | Train PPL:   2.878\n",
            "\t Val. Loss: 1.418 |  Val. PPL:   4.129\n",
            "Epoch: 09 | Time: 0m 11s\n",
            "\tTrain Loss: 0.953 | Train PPL:   2.594\n",
            "\t Val. Loss: 1.365 |  Val. PPL:   3.915\n",
            "Epoch: 10 | Time: 0m 11s\n",
            "\tTrain Loss: 0.860 | Train PPL:   2.364\n",
            "\t Val. Loss: 1.332 |  Val. PPL:   3.787\n",
            "Epoch: 11 | Time: 0m 11s\n",
            "\tTrain Loss: 0.782 | Train PPL:   2.185\n",
            "\t Val. Loss: 1.334 |  Val. PPL:   3.796\n",
            "Epoch: 12 | Time: 0m 11s\n",
            "\tTrain Loss: 0.715 | Train PPL:   2.044\n",
            "\t Val. Loss: 1.307 |  Val. PPL:   3.696\n",
            "Epoch: 13 | Time: 0m 11s\n",
            "\tTrain Loss: 0.658 | Train PPL:   1.930\n",
            "\t Val. Loss: 1.292 |  Val. PPL:   3.640\n",
            "Epoch: 14 | Time: 0m 11s\n",
            "\tTrain Loss: 0.605 | Train PPL:   1.831\n",
            "\t Val. Loss: 1.298 |  Val. PPL:   3.664\n",
            "Epoch: 15 | Time: 0m 11s\n",
            "\tTrain Loss: 0.565 | Train PPL:   1.760\n",
            "\t Val. Loss: 1.286 |  Val. PPL:   3.618\n",
            "Epoch: 16 | Time: 0m 11s\n",
            "\tTrain Loss: 0.531 | Train PPL:   1.701\n",
            "\t Val. Loss: 1.286 |  Val. PPL:   3.618\n",
            "Epoch: 17 | Time: 0m 11s\n",
            "\tTrain Loss: 0.499 | Train PPL:   1.647\n",
            "\t Val. Loss: 1.291 |  Val. PPL:   3.637\n",
            "Epoch: 18 | Time: 0m 11s\n",
            "\tTrain Loss: 0.474 | Train PPL:   1.606\n",
            "\t Val. Loss: 1.294 |  Val. PPL:   3.649\n",
            "Epoch: 19 | Time: 0m 11s\n",
            "\tTrain Loss: 0.446 | Train PPL:   1.561\n",
            "\t Val. Loss: 1.290 |  Val. PPL:   3.632\n",
            "Epoch: 20 | Time: 0m 11s\n",
            "\tTrain Loss: 0.423 | Train PPL:   1.527\n",
            "\t Val. Loss: 1.310 |  Val. PPL:   3.707\n",
            "Epoch: 21 | Time: 0m 11s\n",
            "\tTrain Loss: 0.407 | Train PPL:   1.502\n",
            "\t Val. Loss: 1.307 |  Val. PPL:   3.696\n",
            "Epoch: 22 | Time: 0m 11s\n",
            "\tTrain Loss: 0.386 | Train PPL:   1.471\n",
            "\t Val. Loss: 1.334 |  Val. PPL:   3.795\n",
            "Epoch: 23 | Time: 0m 11s\n",
            "\tTrain Loss: 0.370 | Train PPL:   1.448\n",
            "\t Val. Loss: 1.346 |  Val. PPL:   3.843\n",
            "Epoch: 24 | Time: 0m 11s\n",
            "\tTrain Loss: 0.358 | Train PPL:   1.430\n",
            "\t Val. Loss: 1.345 |  Val. PPL:   3.838\n",
            "Epoch: 25 | Time: 0m 11s\n",
            "\tTrain Loss: 0.343 | Train PPL:   1.409\n",
            "\t Val. Loss: 1.342 |  Val. PPL:   3.826\n",
            "Epoch: 26 | Time: 0m 11s\n",
            "\tTrain Loss: 0.328 | Train PPL:   1.388\n",
            "\t Val. Loss: 1.339 |  Val. PPL:   3.817\n",
            "Epoch: 27 | Time: 0m 11s\n",
            "\tTrain Loss: 0.318 | Train PPL:   1.375\n",
            "\t Val. Loss: 1.348 |  Val. PPL:   3.848\n",
            "Epoch: 28 | Time: 0m 11s\n",
            "\tTrain Loss: 0.304 | Train PPL:   1.355\n",
            "\t Val. Loss: 1.356 |  Val. PPL:   3.882\n",
            "Epoch: 29 | Time: 0m 11s\n",
            "\tTrain Loss: 0.293 | Train PPL:   1.341\n",
            "\t Val. Loss: 1.366 |  Val. PPL:   3.920\n",
            "Epoch: 30 | Time: 0m 11s\n",
            "\tTrain Loss: 0.286 | Train PPL:   1.332\n",
            "\t Val. Loss: 1.376 |  Val. PPL:   3.959\n",
            "Epoch: 31 | Time: 0m 11s\n",
            "\tTrain Loss: 0.274 | Train PPL:   1.316\n",
            "\t Val. Loss: 1.386 |  Val. PPL:   3.999\n",
            "Epoch: 32 | Time: 0m 11s\n",
            "\tTrain Loss: 0.269 | Train PPL:   1.309\n",
            "\t Val. Loss: 1.404 |  Val. PPL:   4.072\n",
            "Epoch: 33 | Time: 0m 11s\n",
            "\tTrain Loss: 0.257 | Train PPL:   1.293\n",
            "\t Val. Loss: 1.422 |  Val. PPL:   4.146\n",
            "Epoch: 34 | Time: 0m 11s\n",
            "\tTrain Loss: 0.251 | Train PPL:   1.285\n",
            "\t Val. Loss: 1.416 |  Val. PPL:   4.119\n",
            "Epoch: 35 | Time: 0m 11s\n",
            "\tTrain Loss: 0.243 | Train PPL:   1.275\n",
            "\t Val. Loss: 1.435 |  Val. PPL:   4.200\n",
            "Epoch: 36 | Time: 0m 11s\n",
            "\tTrain Loss: 0.237 | Train PPL:   1.268\n",
            "\t Val. Loss: 1.420 |  Val. PPL:   4.138\n",
            "Epoch: 37 | Time: 0m 11s\n",
            "\tTrain Loss: 0.229 | Train PPL:   1.258\n",
            "\t Val. Loss: 1.418 |  Val. PPL:   4.127\n",
            "Epoch: 38 | Time: 0m 11s\n",
            "\tTrain Loss: 0.221 | Train PPL:   1.248\n",
            "\t Val. Loss: 1.438 |  Val. PPL:   4.213\n",
            "Epoch: 39 | Time: 0m 11s\n",
            "\tTrain Loss: 0.218 | Train PPL:   1.243\n",
            "\t Val. Loss: 1.455 |  Val. PPL:   4.283\n",
            "Epoch: 40 | Time: 0m 11s\n",
            "\tTrain Loss: 0.212 | Train PPL:   1.236\n",
            "\t Val. Loss: 1.460 |  Val. PPL:   4.306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl4EMRXN_ZTF"
      },
      "source": [
        "### Loading the model and evaluating the outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3_aq7QTPBFc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74414860-586e-407b-c5f1-781eff3068b5"
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 1.286 | Test PPL:   3.618 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlmU1K1g_eQO"
      },
      "source": [
        "### Function to translate the input English sentence and feeding it to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieIjql9uPKH1"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 100):\n",
        "\n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "    # print('tokens for trans :', tokens)\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor,src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:]"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJHNiBOoPQhG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d152c84-644a-4dd9-97eb-22bbea590590"
      },
      "source": [
        "input_id = 12\n",
        "\n",
        "src = vars(train_data.examples[input_id])['Description']\n",
        "trg = vars(train_data.examples[input_id])['Code']\n",
        "\n",
        "print(f'source_sentence = {src}')\n",
        "print(f'target_sentence = {trg}')\n",
        "print(''.join(trg))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source_sentence = ['write', 'a', 'python', 'function', 'to', 'generate', 'sha256', 'for', 'given', 'text']\n",
            "target_sentence = ['def', ' ', 'get_sha256', '(', 'text', ')', ':', '\\n', '\\t', 'import', ' ', 'hashlib', '\\n', '\\t', 'return', ' ', 'hashlib', '.', 'sha256', '(', 'text', ')', '.', 'hexdigest', '(', ')', '\\n', '', '']\n",
            "def get_sha256(text):\n",
            "\timport hashlib\n",
            "\treturn hashlib.sha256(text).hexdigest()\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZSai6VDPR3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57778df2-4cff-4ff7-dad4-7df64458ea9b"
      },
      "source": [
        "# sentence = \"write a program to add two numbers\"\n",
        "code = translate_sentence(src, SRC, TRG, model, device)\n",
        "print(f'predicted target = {code}\\n')\n",
        "\n",
        "print(\"*\"*44)\n",
        "print(\"Predicted Code: \")\n",
        "code = \"\".join(code[:-1]) if code[-1] == '<eos>' else \"\".join(code)\n",
        "print(code)\n",
        "\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted target = ['def', ' ', 'get_sha256', '(', 'text', ')', ':', '\\n', '\\t', 'import', ' ', 'hashlib', '\\n', '\\t', 'return', ' ', 'hashlib', '.', 'hexdigest', '(', ')', '\\n', '', '', '<eos>']\n",
            "\n",
            "********************************************\n",
            "Predicted Code: \n",
            "def get_sha256(text):\n",
            "\timport hashlib\n",
            "\treturn hashlib.hexdigest()\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH38LIApAQ5O"
      },
      "source": [
        "## Prediction of 25 Examples\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FYNJJU1LsbH",
        "outputId": "31999cda-5eba-4007-8923-e2add7d6329c"
      },
      "source": [
        "for input_id in random.choices(range(len(train_data)), k=25):\n",
        "    src = vars(train_data.examples[input_id])['Description']\n",
        "    trg = vars(train_data.examples[input_id])['Code']\n",
        "    print('*'*88)\n",
        "    print(' '.join(src), '\\n')\n",
        "    print('*'*44, 'Given Solution', '*'*44,)\n",
        "    print(''.join(trg))\n",
        "    print('*'*44, 'Predicted Solution', '*'*44)\n",
        "    code = translate_sentence(src, SRC, TRG, model, device)\n",
        "    code = \"\".join(code[:-1]) if code[-1] == '<eos>' else \"\".join(code)\n",
        "    print(code)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****************************************************************************************\n",
            "29 print current day in python \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "from datetime import date\n",
            "today = date.today()\n",
            "print(\"Today's date:\", today)\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "from datetime import datetime\n",
            "now = datetime.now()\n",
            "print(\"Today's date:\", today)\n",
            "\n",
            "****************************************************************************************\n",
            "python math module . \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "import random\n",
            "print(random.random() * 100 - 5)\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "import random\n",
            "print(random.random() * 100)\n",
            "\n",
            "****************************************************************************************\n",
            "write python program to count the number of words in a text file \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "fname = input(\"Enter file name: \")\n",
            "num_words = 0\n",
            "with open(fname, 'r') as f:\n",
            "\tfor line in f:\n",
            "\twords = line.split()\n",
            "\tnum_words += len(words)\n",
            "print(\"Number of words:\")\n",
            "print(num_words)\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "\n",
            "\n",
            "fname = input(\"Enter file name: \")\n",
            "num_lines = 0\n",
            "with open(fname, 'r') as f:\n",
            "\tfor line in f:\n",
            "\twords = line.split()\n",
            "\twords.split()\n",
            "\tnum_words += len(words)\n",
            "print(\"Number of words:\")\n",
            "print(num_words)\n",
            "\n",
            "****************************************************************************************\n",
            "second one into the first \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "a = {\"a\": 1, \"b\": 3}\n",
            "b = {\"c\": 1, \"d\": 3}\n",
            "a.update(b)\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "a = {\"a\": 1, \"b\": \"c\": 1, 3}\n",
            "b = {\"c\": \"d\": \"d\": 4}\n",
            "a.update(b)\n",
            "\n",
            "****************************************************************************************\n",
            "ar[i]+ar[j ] is divisible by k in a data list \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "def divisible_sum_pairs(arr, k):\n",
            "\tcount = 0\n",
            "\tn = len(arr)\n",
            "\tfor i in range(n - 1):\n",
            "\tj = i + 1\n",
            "\twhile j < n:\n",
            "        if ((arr[i] + arr[j]) % k) == 0:\n",
            "            count += 1\n",
            "        j += 1\n",
            "\treturn count\n",
            "\n",
            "\n",
            "import math\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "def divisible_sum_pairs(arr, k):\n",
            "\tcount = 0\n",
            "\tfor i in range(n + 1):\n",
            "\tj = i i + i\n",
            "\tif j % i == 0:\n",
            "        k += j\n",
            "        k += j\n",
            "\tprint(j)\n",
            "\n",
            "****************************************************************************************\n",
            "write a python function to convert iterable to pairwise iterable \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "def pairwise(iterable):\n",
            "\tfrom itertools import tee\n",
            "\ta, b = tee(iterable)\n",
            "\tnext(b, None)\n",
            "\treturn zip(a, b)\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "def pairwise(iterable):\n",
            "\tfrom itertools import tee\n",
            "\ta, b = tee(iterable)\n",
            "\tnext(b, zip(a, b))\n",
            "\treturn zip(a, b)\n",
            "\n",
            "****************************************************************************************\n",
            "check if the number of terms is valid \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "if nterms <= 0:\n",
            "\tprint(\"Plese enter a positive integer\")\n",
            "elif nterms == 1:\n",
            "\tprint(\"Fibonacci sequence:\")\n",
            "\tprint(n1)\n",
            "else:\n",
            "\tprint(\"Fibonacci sequence:\")\n",
            "\tprint(n1, \",\", n2, end=', ')\n",
            "\twhile count < nterms:\n",
            "\tnth = n1 + n2\n",
            "\tprint(nth, end=' , ')\n",
            "\n",
            "\tn1 = n2\n",
            "\tn2 = nth\n",
            "\tcount += 1\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "if nterms <= 0:\n",
            "\tprint(\"Please enter a positive integer\")\n",
            "elif nterms == 1:\n",
            "\tprint(\"Fibonacci sequence upto\", nterms, \":\")\n",
            "\tprint(n1)\n",
            "else:\n",
            "\tprint(\"Fibonacci sequence:\")\n",
            "\twhile count < nterms:\n",
            "\tprint(n1)\n",
            "\tprint(n1)\n",
            "\tn1 = n1 n2\n",
            "\tcount += 1\n",
            "\tcount 1\n",
            "\n",
            "****************************************************************************************\n",
            "write a program to get 3rd and last character of a given string \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "\n",
            "\n",
            "string = \"Good Night\"\n",
            "print(\"\\nSlicing characters between \"\n",
            "      + \"3rd and last character: \")\n",
            "print(string[3:-1])\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "\n",
            "\n",
            "str1 = \"Good Night\"\n",
            "print(\"\\nSlicing characters between \"\n",
            "      + \"3rd and last character: \")\n",
            "print(string[3:-1])\n",
            "\n",
            "****************************************************************************************\n",
            "66 write a program to transpose a matrix using a nested loop \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "\n",
            "\n",
            "X = [[12, 7],\n",
            "     [4, 5],\n",
            "     [3, 8]]\n",
            "\n",
            "\n",
            "result = [[0, 0, 0],\n",
            "          [0, 0, 0]]\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "\n",
            "\n",
            "X = [[12, 7],\n",
            "     [3],\n",
            "     [4, 5,\n",
            "     [6]]\n",
            "     [7,\n",
            "     [8, 9]]\n",
            "\n",
            "\n",
            "Y = [[5, 0, 0,\n",
            "     [0, 0],\n",
            "     [0, 0],\n",
            "     [0]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "****************************************************************************************\n",
            "incremented date if it is \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "\n",
            "\n",
            "date = \"20/04/2021\"\n",
            "dd, mm, yy = date.split('/')\n",
            "dd = int(dd)\n",
            "mm = int(mm)\n",
            "yy = int(yy)\n",
            "if num == 0:\n",
            "\treturn 0\n",
            "else:\n",
            "\treturn num % 10 + sumDigits(int(num / 10))\n",
            "if (7 or mm == 8 or mm == 10 or mm == 12):\n",
            "\tmax1 = 31\n",
            "elif(mm == 4 or mm == 6 or mm == 9 or mm == 11):\n",
            "\tmax1 = 30\n",
            "elif(yy % 4 == 0 and yy % 100 != 0 or yy % 400 == 0):\n",
            "\tmax1 = 29\n",
            "else:\n",
            "\tmax1 = 28\n",
            "if(mm < 1 or mm > 12):\n",
            "\tprint(\"Date is invalid.\")\n",
            "elif(dd < 1 or dd > max1):\n",
            "\tprint(\"Date is invalid.\")\n",
            "elif(dd == max1 and mm != 12):\n",
            "\tdd = 1\n",
            "\tmm = mm + 1\n",
            "\tprint(\"The incremented date is: \", dd, mm, yy)\n",
            "elif(dd == 31 and mm == 12):\n",
            "\tdd = 1\n",
            "\tmm = 1\n",
            "\tyy = yy + 1\n",
            "\tprint(\"The incremented date is: \", dd, mm, yy)\n",
            "else:\n",
            "\tdd = dd + 1\n",
            "\tprint(\"The incremented date is: \", dd, mm, yy)\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "\n",
            "\n",
            "import datetime\n",
            "\n",
            "\n",
            "def get_attributes_from_date(yy, mm):\n",
            "\tif(mm == or mm):\n",
            "\tprint(mm == 5 or == 6 7 == 0):\n",
            "\tprint(\"Date is invalid.\")\n",
            "\tfor i in range(1, end=\"\"):\n",
            "\tprint(i + 1)\n",
            "\twhile(i <= and (\"The incremented date is: \"\n",
            "****************************************************************************************\n",
            "( gcd)(euclidean algorithm ) and print the result . \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "\n",
            "\n",
            "a = int(input())\n",
            "b = int(input())\n",
            "\n",
            "\n",
            "while a != 0 and b != 0:\n",
            "\tif a > b:\n",
            "\ta %= b\n",
            "\telse:\n",
            "\tb %= a\n",
            "\n",
            "\n",
            "gcd = a + b\n",
            "print(gcd)\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "\n",
            "\n",
            "a = int(input())\n",
            "b = input()\n",
            "\n",
            "a = b\n",
            "\n",
            "b = a + b\n",
            "\n",
            "\n",
            "\n",
            "a = a b a + b\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "print(gcd)\n",
            "\n",
            "****************************************************************************************\n",
            "value using any ( ) + map ( ) + lambda \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "test_tup = (10, 4, 5, 6, None)\n",
            "res = any(map(lambda ele: ele is None, test_tup))\n",
            "print(\"Does tuple contain any None value ? : \" + str(res))\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "\n",
            "\n",
            "test_dict = {'gfg': 4, 'best': 5, 'best': 7, 'best': 2}\n",
            "print(\"The original list : \" + str(test_list))\n",
            "\n",
            "\n",
            "\n",
            "res = {}\n",
            "for sub in test_list: test_str.items()\n",
            "\tprint(\"Does tuple contain any None value ? : \" + str(res))\n",
            "\n",
            "****************************************************************************************\n",
            "string and print it \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "\n",
            "\n",
            "l = ['hello', 'guys', 'have',\n",
            "     'a', 'nice', 'day']\n",
            "l = ' '.join(l)\n",
            "print(l)\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "\n",
            "\n",
            "str1 = \"python1234\"\n",
            "total_digits = 0\n",
            "total_letters = 0\n",
            "for i in range(len(str1)):\n",
            "\tif(letter.isnumeric() == or letter.isnumeric()):\n",
            "\ttotal_digits += 1\n",
            "\telse:\n",
            "\ttotal_letters += 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "print(\"Total letters found : \", total_letters)\n",
            "print(\"Total digits found : \", total_digits)\n",
            "\n",
            "****************************************************************************************\n",
            "console and print the evaluation result . \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "expression = input()\n",
            "print(eval(expression))\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "expression = input()\n",
            "print(eval(input(expression)))\n",
            "\n",
            "****************************************************************************************\n",
            "principle amount , rate of interest and time is given \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "def compound_interest(p, r, t):\n",
            "\tci = p * (pow((1 + r / 100), t))\n",
            "\treturn ci\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "def compound_interest(p, r, t):\n",
            "\tci = p * r * t\n",
            "\treturn ci\n",
            "\n",
            "****************************************************************************************\n",
            "and prints it . \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "test_list = [{'END': [5, 6, 5]}, {'is': [10, 2, 3]}, {'best': [4, 3, 1]}]\n",
            "res = [{} for idx in range(len(test_list))]\n",
            "idx = 0\n",
            "for sub in test_list:\n",
            "\tfor key, val in sub.items():\n",
            "\tfor ele in val:\n",
            "        res[idx][key] = ele\n",
            "        idx += 1\n",
            "\tidx = 0\n",
            "print(\"Records after conversion : \" + str(res))\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "test_list = [{'END': [5, 6, 5, 6, 3], [7, 3, 5, 6, 7]},\n",
            "             {'tsai': [7, 8, 9, 10, 10, 10, 9]}\n",
            "res = [0, 0]\n",
            "for idx in range(len(test_list):\n",
            "\tfor \n",
            "****************************************************************************************\n",
            "takes in base , height as input \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "def area_shape(base, height, shape):\n",
            "\treturn {'triangle': 0.5 * base * height, 'parallelogram': base * height}[shape]\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "def area_shape(base, height, shape):\n",
            "\treturn {'triangle': 0.5 * base * height, 'parallelogram': base * height}\n",
            "\n",
            "****************************************************************************************\n",
            "result is 3x4 \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "result = [[0, 0, 0, 0],\n",
            "          [0, 0, 0, 0],\n",
            "          [0, 0, 0, 0]]\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "result = [0, 0, 0, 0, 0]\n",
            "          [0, 0, 0, 0]\n",
            "\n",
            "****************************************************************************************\n",
            "3x4 matrix \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "Y = [[5, 8, 1, 2],\n",
            "     [6, 7, 3, 0],\n",
            "     [4, 5, 9, 1]]\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "Y = [[5, 3, 0, 0],\n",
            "     [4, 5, 6],\n",
            "     [7, 8, 9]\n",
            "     [1, 0, 0, 0]\n",
            "     [0, 0, 0, 0]\n",
            "\n",
            "****************************************************************************************\n",
            "from a sentence \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "\n",
            "\n",
            "sentence = input(\"Enter a sentence : \")\n",
            "\n",
            "\n",
            "def fn(sentence):\n",
            "\tvowels = 'aeiou'\n",
            "\treturn ''.join([l for l in sentence if l not in vowels])\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "sentence = 'the quick brown fox'\n",
            "print(sentence[::3])\n",
            "\n",
            "****************************************************************************************\n",
            "write a python program that multiplies a tuple n times and print the result \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "my_tuple = (1, 2, 3)\n",
            "n = 3\n",
            "print(my_tuple * 3)\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "my_tuple = (1, 2, 3)\n",
            "n = 3\n",
            "n = 3\n",
            "print(my_tuple * 3)\n",
            "\n",
            "****************************************************************************************\n",
            "write a python function for bitwise division with given number of shifts \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "def bit_div(n, shift):\n",
            "\treturn n >> shift\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "def bit_div(n, shift):\n",
            "\treturn n >> shift\n",
            "\n",
            "****************************************************************************************\n",
            "write a python function to find the sum of cosine series \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "\n",
            "\n",
            "def cosine(x, n):\n",
            "\tcosx = 1\n",
            "\tsign = -1\n",
            "\tfor i in range(2, n, 2):\n",
            "\tpi = 22 / 7\n",
            "\ty = x * (pi / 180)\n",
            "\tcosx = cosx + (sign * (y**i)) / math.factorial(i)\n",
            "\tsign = -sign\n",
            "\treturn cosx\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "\n",
            "\n",
            "def cosine(x, n):\n",
            "\tcosx = 1\n",
            "\tcosx = 22 / 7\n",
            "\ty = 22 / 7\n",
            "\tcosx = 22 / y\n",
            "\tsign = i\n",
            "\tsign = i\n",
            "\tsign = i\n",
            "\tsign = cosx cosx + + i\n",
            "\tsign = cosx\n",
            "\tsign cosx\n",
            "****************************************************************************************\n",
            "string in lexicographic sorted order . \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "def get_ordered_permutations(word, k):\n",
            "\t[print(''.join(x)) for x in sorted(list(permutations(word, int(k))))]\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "def get_ordered_permutations(word, k):\n",
            "\t[print(''.join(x, x))\n",
            "\n",
            "****************************************************************************************\n",
            "percentage \n",
            "\n",
            "******************************************** Given Solution ********************************************\n",
            "def cal_sp_after_discount(sp: float, discount: float) -> float:\n",
            "\treturn sp * (1 - discount / 100)\n",
            "\n",
            "******************************************** Predicted Solution ********************************************\n",
            "def cal_sp_after_discount(sp: float, discount: float) -> float:\n",
            "\treturn sp * (1 - discount / 100)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTBipndfPOlX"
      },
      "source": [
        "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 4, n_cols = 2):\n",
        "    \n",
        "    assert n_rows * n_cols == n_heads\n",
        "    \n",
        "    fig = plt.figure(figsize=(15,25))\n",
        "    \n",
        "    for i in range(n_heads):\n",
        "        \n",
        "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
        "        \n",
        "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
        "\n",
        "        cax = ax.matshow(_attention, cmap='bone')\n",
        "\n",
        "        ax.tick_params(labelsize=12)\n",
        "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
        "                           rotation=45)\n",
        "        ax.set_yticklabels(['']+translation)\n",
        "\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHWqhmvtPTJv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "0d6c5856-5cd3-47f0-9039-28e1ac89d096"
      },
      "source": [
        "display_attention(src, trg, attention)\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-b6e72981ead8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'attention' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YyJFiJXPVjr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b11c4b54-8ac1-4713-f596-ab0eaf85200c"
      },
      "source": [
        "example_idx = 6\n",
        "\n",
        "src = vars(valid_data.examples[example_idx])['src']\n",
        "trg = vars(valid_data.examples[example_idx])['trg']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-6728fd0fe0f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'valid_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDmsvAhoPWze",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "820fa6bf-44cd-4abe-8f9d-70bcb64b2ca9"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-2dedbc49537d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSRC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'predicted trg = {translation}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k_YvNBPPX02"
      },
      "source": [
        "display_attention(src, translation, attention)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4RJbrqmPZkX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "14636eed-f43a-4a64-b6e0-c2ae60878bee"
      },
      "source": [
        "example_idx = 10\n",
        "\n",
        "src = vars(test_data.examples[example_idx])['src']\n",
        "trg = vars(test_data.examples[example_idx])['trg']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-43a1d829f584>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'src'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN00r7FqPbGj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "d20b8369-5034-48d0-832d-f4a2c9011d32"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-2dedbc49537d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSRC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'predicted trg = {translation}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixzIycViPcI3"
      },
      "source": [
        "display_attention(src, translation, attention)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksrj1V2YPeCa"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 250):\n",
        "    \n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    \n",
        "    for datum in data:\n",
        "        \n",
        "        src = vars(datum)['src']\n",
        "        trg = vars(datum)['trg']\n",
        "        \n",
        "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
        "        \n",
        "        #cut off <eos> token\n",
        "        pred_trg = pred_trg[:-1]\n",
        "        \n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "        \n",
        "    return bleu_score(pred_trgs, trgs)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWnMnm_UPfNp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "7b628755-e162-4c36-eebd-94b30ee97d4a"
      },
      "source": [
        "bleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\n",
        "\n",
        "print(f'BLEU score = {bleu_score*100:.2f}')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-fdbcc13fd3c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbleu_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSRC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'BLEU score = {bleu_score*100:.2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-e020993db885>\u001b[0m in \u001b[0;36mcalculate_bleu\u001b[0;34m(data, src_field, trg_field, model, device, max_len)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdatum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'src'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBp2QYMzQM4F"
      },
      "source": [
        "torch.zeros(5).unsqueeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk7J4Mj4fqs1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}